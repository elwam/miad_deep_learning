{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('trainReg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77779, 92)\n",
      "Index(['ID', 'Y', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
      "       'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40',\n",
      "       'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50',\n",
      "       'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60',\n",
      "       'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70',\n",
      "       'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80',\n",
      "       'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V88</th>\n",
       "      <th>V89</th>\n",
       "      <th>V90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>44.81144</td>\n",
       "      <td>0.83826</td>\n",
       "      <td>0</td>\n",
       "      <td>7.91314</td>\n",
       "      <td>10.94148</td>\n",
       "      <td>-0.04547</td>\n",
       "      <td>-15.16332</td>\n",
       "      <td>-10.47324</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.44873</td>\n",
       "      <td>-230.30484</td>\n",
       "      <td>-40.94698</td>\n",
       "      <td>48.20025</td>\n",
       "      <td>-0.28694</td>\n",
       "      <td>155.76251</td>\n",
       "      <td>-56.23579</td>\n",
       "      <td>13.62599</td>\n",
       "      <td>123.92018</td>\n",
       "      <td>10.02845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1998</td>\n",
       "      <td>41.99180</td>\n",
       "      <td>7.99976</td>\n",
       "      <td>0</td>\n",
       "      <td>64.26707</td>\n",
       "      <td>16.54115</td>\n",
       "      <td>-9.28737</td>\n",
       "      <td>-40.73524</td>\n",
       "      <td>33.60440</td>\n",
       "      <td>...</td>\n",
       "      <td>18.68972</td>\n",
       "      <td>-44.06062</td>\n",
       "      <td>52.37792</td>\n",
       "      <td>81.36093</td>\n",
       "      <td>-14.81111</td>\n",
       "      <td>151.66273</td>\n",
       "      <td>-120.61213</td>\n",
       "      <td>10.57519</td>\n",
       "      <td>-3.21078</td>\n",
       "      <td>-1.07438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>42.19196</td>\n",
       "      <td>2.23111</td>\n",
       "      <td>0</td>\n",
       "      <td>65.07719</td>\n",
       "      <td>24.99746</td>\n",
       "      <td>1.76100</td>\n",
       "      <td>6.66573</td>\n",
       "      <td>3.45778</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.69878</td>\n",
       "      <td>-118.95712</td>\n",
       "      <td>54.15529</td>\n",
       "      <td>-23.32168</td>\n",
       "      <td>-9.65067</td>\n",
       "      <td>-83.83055</td>\n",
       "      <td>-141.17594</td>\n",
       "      <td>7.33084</td>\n",
       "      <td>-275.69714</td>\n",
       "      <td>2.35522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1998</td>\n",
       "      <td>39.28634</td>\n",
       "      <td>-1.85716</td>\n",
       "      <td>0</td>\n",
       "      <td>91.04190</td>\n",
       "      <td>9.08333</td>\n",
       "      <td>0.08502</td>\n",
       "      <td>-5.59216</td>\n",
       "      <td>65.62463</td>\n",
       "      <td>...</td>\n",
       "      <td>20.89044</td>\n",
       "      <td>-18.53135</td>\n",
       "      <td>176.09769</td>\n",
       "      <td>351.33669</td>\n",
       "      <td>3.44682</td>\n",
       "      <td>121.69156</td>\n",
       "      <td>-270.43989</td>\n",
       "      <td>12.51659</td>\n",
       "      <td>-140.88884</td>\n",
       "      <td>-0.23476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1998</td>\n",
       "      <td>40.36025</td>\n",
       "      <td>2.94918</td>\n",
       "      <td>0</td>\n",
       "      <td>53.83723</td>\n",
       "      <td>13.71369</td>\n",
       "      <td>-8.21964</td>\n",
       "      <td>-40.21636</td>\n",
       "      <td>21.22366</td>\n",
       "      <td>...</td>\n",
       "      <td>19.91979</td>\n",
       "      <td>34.59026</td>\n",
       "      <td>-69.83720</td>\n",
       "      <td>102.31946</td>\n",
       "      <td>8.08807</td>\n",
       "      <td>135.08089</td>\n",
       "      <td>-153.02327</td>\n",
       "      <td>4.09207</td>\n",
       "      <td>-68.33046</td>\n",
       "      <td>-6.19159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Y        V1       V2  V3        V4        V5       V6        V7  \\\n",
       "0   1  2013  44.81144  0.83826   0   7.91314  10.94148 -0.04547 -15.16332   \n",
       "1   2  1998  41.99180  7.99976   0  64.26707  16.54115 -9.28737 -40.73524   \n",
       "2   3  1998  42.19196  2.23111   0  65.07719  24.99746  1.76100   6.66573   \n",
       "3   4  1998  39.28634 -1.85716   0  91.04190   9.08333  0.08502  -5.59216   \n",
       "4   5  1998  40.36025  2.94918   0  53.83723  13.71369 -8.21964 -40.21636   \n",
       "\n",
       "         V8  ...       V81        V82        V83        V84       V85  \\\n",
       "0 -10.47324  ...  -8.44873 -230.30484  -40.94698   48.20025  -0.28694   \n",
       "1  33.60440  ...  18.68972  -44.06062   52.37792   81.36093 -14.81111   \n",
       "2   3.45778  ...  -3.69878 -118.95712   54.15529  -23.32168  -9.65067   \n",
       "3  65.62463  ...  20.89044  -18.53135  176.09769  351.33669   3.44682   \n",
       "4  21.22366  ...  19.91979   34.59026  -69.83720  102.31946   8.08807   \n",
       "\n",
       "         V86        V87       V88        V89       V90  \n",
       "0  155.76251  -56.23579  13.62599  123.92018  10.02845  \n",
       "1  151.66273 -120.61213  10.57519   -3.21078  -1.07438  \n",
       "2  -83.83055 -141.17594   7.33084 -275.69714   2.35522  \n",
       "3  121.69156 -270.43989  12.51659 -140.88884  -0.23476  \n",
       "4  135.08089 -153.02327   4.09207  -68.33046  -6.19159  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 474947.9375 - val_loss: 61873.3398\n",
      "Epoch 2/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 115260.1484 - val_loss: 17284.9941\n",
      "Epoch 3/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 92500.3516 - val_loss: 11113.0000\n",
      "Epoch 4/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 87120.7656 - val_loss: 4752.4790\n",
      "Epoch 5/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 84008.7344 - val_loss: 5258.8325\n",
      "Epoch 6/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 82016.4922 - val_loss: 4068.7717\n",
      "Epoch 7/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 80321.0859 - val_loss: 5965.4507\n",
      "Epoch 8/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 80142.5703 - val_loss: 4909.0835\n",
      "Epoch 9/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 79053.8516 - val_loss: 3004.7070\n",
      "Epoch 10/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 79348.3125 - val_loss: 2815.4421\n",
      "Epoch 11/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 78878.3750 - val_loss: 8473.2510\n",
      "Epoch 12/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 77810.9922 - val_loss: 7447.7163\n",
      "Epoch 13/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 77223.7891 - val_loss: 9853.6592\n",
      "Epoch 14/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 77889.9219 - val_loss: 2153.6023\n",
      "Epoch 15/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 76644.5781 - val_loss: 8440.7783\n",
      "Epoch 16/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 76718.2812 - val_loss: 2069.6331\n",
      "Epoch 17/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 75467.1250 - val_loss: 1626.6603\n",
      "Epoch 18/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 73970.6797 - val_loss: 3875.5093\n",
      "Epoch 19/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 74197.5312 - val_loss: 4676.5679\n",
      "Epoch 20/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 74639.2656 - val_loss: 4398.7876\n",
      "Epoch 21/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 73386.5547 - val_loss: 3818.0254\n",
      "Epoch 22/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 72545.1406 - val_loss: 2562.5664\n",
      "Epoch 23/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 71278.1641 - val_loss: 1430.0858\n",
      "Epoch 24/50\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 71513.6641 - val_loss: 4616.6001\n",
      "Epoch 25/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 70246.9688 - val_loss: 7014.8149\n",
      "Epoch 26/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 70908.6562 - val_loss: 3111.1050\n",
      "Epoch 27/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 69376.0859 - val_loss: 5154.5161\n",
      "Epoch 28/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 69504.2578 - val_loss: 644.5491\n",
      "Epoch 29/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 69067.8359 - val_loss: 617.0854\n",
      "Epoch 30/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 67844.1172 - val_loss: 8219.7871\n",
      "Epoch 31/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 67539.5859 - val_loss: 1704.4988\n",
      "Epoch 32/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 67026.3750 - val_loss: 1379.4226\n",
      "Epoch 33/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 66484.9141 - val_loss: 5395.9961\n",
      "Epoch 34/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 67247.7812 - val_loss: 4673.7026\n",
      "Epoch 35/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 66671.0781 - val_loss: 2304.2241\n",
      "Epoch 36/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 65882.0859 - val_loss: 1631.5922\n",
      "Epoch 37/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 65363.8867 - val_loss: 5740.5869\n",
      "Epoch 38/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 64683.7109 - val_loss: 9992.6924\n",
      "Epoch 39/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 65031.3086 - val_loss: 533.3749\n",
      "Epoch 40/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 64705.5039 - val_loss: 1883.0112\n",
      "Epoch 41/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 64356.9336 - val_loss: 966.2379\n",
      "Epoch 42/50\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 63908.8398 - val_loss: 2127.7312\n",
      "Epoch 43/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 63858.6523 - val_loss: 929.0692\n",
      "Epoch 44/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62785.9648 - val_loss: 575.8995\n",
      "Epoch 45/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62363.4023 - val_loss: 2724.0161\n",
      "Epoch 46/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62610.3398 - val_loss: 509.0727\n",
      "Epoch 47/50\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 61720.9414 - val_loss: 1372.4093\n",
      "Epoch 48/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62349.9414 - val_loss: 579.4811\n",
      "Epoch 49/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 60654.0781 - val_loss: 1141.4034\n",
      "Epoch 50/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 61306.8906 - val_loss: 835.7725\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 846.7103\n",
      "Loss en el conjunto de prueba: 846.7102661132812\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en características (X) y etiquetas (Y)\n",
    "X = data.drop(['ID', 'Y'], axis=1).values\n",
    "Y = data['Y'].values\n",
    "\n",
    "# Escalar las características para mejorar el rendimiento del modelo\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construir el modelo de red neuronal\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_split=0.1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss en el conjunto de prueba:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 600785.5000 - val_loss: 97696.8828 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 90038.8672 - val_loss: 27436.4336 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 48270.4648 - val_loss: 9375.0361 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 36954.2852 - val_loss: 4171.8398 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 33534.0664 - val_loss: 2560.3477 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 32160.3809 - val_loss: 2661.2498 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 30772.3809 - val_loss: 1690.9557 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 30793.3770 - val_loss: 1519.0140 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 30362.2559 - val_loss: 1338.0867 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29982.6387 - val_loss: 1544.0146 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 29851.7422 - val_loss: 1316.2700 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29768.8906 - val_loss: 1312.8149 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29231.4668 - val_loss: 1357.1467 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29056.9531 - val_loss: 1989.8628 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29123.7051 - val_loss: 1643.7095 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29153.1289 - val_loss: 1643.3069 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29045.9102 - val_loss: 1243.8400 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29353.3027 - val_loss: 1265.0123 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28728.7930 - val_loss: 1068.7877 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29019.5859 - val_loss: 1284.8647 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 28336.1309 - val_loss: 1422.1992 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 28721.5156 - val_loss: 1225.1775 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28370.4648 - val_loss: 603.1976 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28162.9316 - val_loss: 2192.0381 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28309.9238 - val_loss: 1421.9156 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28343.5996 - val_loss: 1016.8364 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28178.9746 - val_loss: 1733.4520 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27962.7598 - val_loss: 657.0676 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27543.5879 - val_loss: 559.0237 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27109.5820 - val_loss: 469.5639 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27206.4043 - val_loss: 412.9561 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27160.2539 - val_loss: 586.2923 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26895.7188 - val_loss: 479.3074 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26922.4023 - val_loss: 536.3222 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26876.1895 - val_loss: 460.2358 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26997.7441 - val_loss: 503.3688 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26870.1836 - val_loss: 276.3347 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26934.0820 - val_loss: 491.7870 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27089.4219 - val_loss: 374.4857 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26820.9141 - val_loss: 201.7317 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26776.4395 - val_loss: 315.9775 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26954.3086 - val_loss: 341.7509 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26772.8496 - val_loss: 214.0721 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26852.5684 - val_loss: 272.4501 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26811.6113 - val_loss: 250.2004 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26631.4180 - val_loss: 272.0569 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26700.5371 - val_loss: 406.7640 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26553.5293 - val_loss: 405.7386 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26915.3945 - val_loss: 361.1223 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26759.5566 - val_loss: 387.4381 - lr: 1.0000e-04\n",
      "487/487 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calcular el RMSE en el conjunto de datos de prueba\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(Y_test, predictions))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE en el conjunto de prueba:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "# Red 2 \n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Definir el modelo\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Añadir reducción de la tasa de aprendizaje en meseta\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_split=0.1, callbacks=[reduce_lr])\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de prueba: 19.951228276989834\n"
     ]
    }
   ],
   "source": [
    "# Calcular el RMSE en el conjunto de datos de prueba\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 1118700.8750 - root_mean_squared_error: 1057.6865 - val_loss: 247950.2812 - val_root_mean_squared_error: 497.9461\n",
      "Epoch 2/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 179927.5938 - root_mean_squared_error: 424.1787 - val_loss: 122805.6719 - val_root_mean_squared_error: 350.4364\n",
      "Epoch 3/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 97720.4219 - root_mean_squared_error: 312.6027 - val_loss: 65685.0156 - val_root_mean_squared_error: 256.2909\n",
      "Epoch 4/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 55538.1719 - root_mean_squared_error: 235.6654 - val_loss: 32725.0547 - val_root_mean_squared_error: 180.9007\n",
      "Epoch 5/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 31415.9238 - root_mean_squared_error: 177.2454 - val_loss: 15287.2031 - val_root_mean_squared_error: 123.6414\n",
      "Epoch 6/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 20381.7754 - root_mean_squared_error: 142.7648 - val_loss: 8050.4966 - val_root_mean_squared_error: 89.7246\n",
      "Epoch 7/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 15824.4814 - root_mean_squared_error: 125.7954 - val_loss: 4475.0005 - val_root_mean_squared_error: 66.8954\n",
      "Epoch 8/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 13239.4111 - root_mean_squared_error: 115.0626 - val_loss: 3652.4185 - val_root_mean_squared_error: 60.4352\n",
      "Epoch 9/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 11868.3623 - root_mean_squared_error: 108.9420 - val_loss: 2899.7188 - val_root_mean_squared_error: 53.8490\n",
      "Epoch 10/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 11004.0596 - root_mean_squared_error: 104.9002 - val_loss: 1919.8907 - val_root_mean_squared_error: 43.8166\n",
      "Epoch 11/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 10192.4541 - root_mean_squared_error: 100.9577 - val_loss: 1935.3912 - val_root_mean_squared_error: 43.9931\n",
      "Epoch 12/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 9600.1055 - root_mean_squared_error: 97.9801 - val_loss: 1548.4659 - val_root_mean_squared_error: 39.3506\n",
      "Epoch 13/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 9184.8232 - root_mean_squared_error: 95.8375 - val_loss: 1421.3236 - val_root_mean_squared_error: 37.7004\n",
      "Epoch 14/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8827.3613 - root_mean_squared_error: 93.9540 - val_loss: 1116.6229 - val_root_mean_squared_error: 33.4159\n",
      "Epoch 15/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8438.0547 - root_mean_squared_error: 91.8589 - val_loss: 946.9946 - val_root_mean_squared_error: 30.7733\n",
      "Epoch 16/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8398.1729 - root_mean_squared_error: 91.6415 - val_loss: 725.1652 - val_root_mean_squared_error: 26.9289\n",
      "Epoch 17/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 7963.9033 - root_mean_squared_error: 89.2407 - val_loss: 1106.7396 - val_root_mean_squared_error: 33.2677\n",
      "Epoch 18/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8022.3867 - root_mean_squared_error: 89.5678 - val_loss: 726.4359 - val_root_mean_squared_error: 26.9525\n",
      "Epoch 19/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7751.2773 - root_mean_squared_error: 88.0413 - val_loss: 1143.7322 - val_root_mean_squared_error: 33.8191\n",
      "Epoch 20/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7706.4209 - root_mean_squared_error: 87.7862 - val_loss: 561.7839 - val_root_mean_squared_error: 23.7020\n",
      "Epoch 21/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7495.1196 - root_mean_squared_error: 86.5744 - val_loss: 683.3547 - val_root_mean_squared_error: 26.1411\n",
      "Epoch 22/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7418.7505 - root_mean_squared_error: 86.1322 - val_loss: 663.6052 - val_root_mean_squared_error: 25.7605\n",
      "Epoch 23/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7293.0801 - root_mean_squared_error: 85.3995 - val_loss: 479.0306 - val_root_mean_squared_error: 21.8868\n",
      "Epoch 24/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7151.0596 - root_mean_squared_error: 84.5639 - val_loss: 1277.8113 - val_root_mean_squared_error: 35.7465\n",
      "Epoch 25/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7211.5034 - root_mean_squared_error: 84.9206 - val_loss: 577.5351 - val_root_mean_squared_error: 24.0320\n",
      "Epoch 26/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7035.1367 - root_mean_squared_error: 83.8757 - val_loss: 387.6982 - val_root_mean_squared_error: 19.6901\n",
      "Epoch 27/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6712.4766 - root_mean_squared_error: 81.9297 - val_loss: 485.6389 - val_root_mean_squared_error: 22.0372\n",
      "Epoch 28/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6711.5728 - root_mean_squared_error: 81.9242 - val_loss: 362.6979 - val_root_mean_squared_error: 19.0446\n",
      "Epoch 29/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6627.0244 - root_mean_squared_error: 81.4065 - val_loss: 512.6206 - val_root_mean_squared_error: 22.6411\n",
      "Epoch 30/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6446.3120 - root_mean_squared_error: 80.2889 - val_loss: 549.2762 - val_root_mean_squared_error: 23.4366\n",
      "Epoch 31/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6224.2495 - root_mean_squared_error: 78.8939 - val_loss: 1113.1095 - val_root_mean_squared_error: 33.3633\n",
      "Epoch 32/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6249.7900 - root_mean_squared_error: 79.0556 - val_loss: 750.8727 - val_root_mean_squared_error: 27.4021\n",
      "Epoch 33/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 6138.7812 - root_mean_squared_error: 78.3504 - val_loss: 893.2844 - val_root_mean_squared_error: 29.8879\n",
      "Epoch 34/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5954.4932 - root_mean_squared_error: 77.1654 - val_loss: 528.0327 - val_root_mean_squared_error: 22.9790\n",
      "Epoch 35/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5851.0513 - root_mean_squared_error: 76.4922 - val_loss: 335.4610 - val_root_mean_squared_error: 18.3156\n",
      "Epoch 36/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5816.8970 - root_mean_squared_error: 76.2686 - val_loss: 287.2848 - val_root_mean_squared_error: 16.9495\n",
      "Epoch 37/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5682.5815 - root_mean_squared_error: 75.3829 - val_loss: 405.9785 - val_root_mean_squared_error: 20.1489\n",
      "Epoch 38/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5580.2617 - root_mean_squared_error: 74.7011 - val_loss: 597.1459 - val_root_mean_squared_error: 24.4366\n",
      "Epoch 39/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5398.4805 - root_mean_squared_error: 73.4743 - val_loss: 324.6689 - val_root_mean_squared_error: 18.0186\n",
      "Epoch 40/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5307.9673 - root_mean_squared_error: 72.8558 - val_loss: 370.3709 - val_root_mean_squared_error: 19.2450\n",
      "Epoch 41/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5144.1724 - root_mean_squared_error: 71.7229 - val_loss: 349.2915 - val_root_mean_squared_error: 18.6893\n",
      "Epoch 42/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5096.8105 - root_mean_squared_error: 71.3920 - val_loss: 567.3909 - val_root_mean_squared_error: 23.8200\n",
      "Epoch 43/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4887.1191 - root_mean_squared_error: 69.9079 - val_loss: 434.1218 - val_root_mean_squared_error: 20.8356\n",
      "Epoch 44/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4794.3945 - root_mean_squared_error: 69.2416 - val_loss: 632.7292 - val_root_mean_squared_error: 25.1541\n",
      "Epoch 45/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4702.1479 - root_mean_squared_error: 68.5722 - val_loss: 610.0547 - val_root_mean_squared_error: 24.6993\n",
      "Epoch 46/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4547.4902 - root_mean_squared_error: 67.4351 - val_loss: 299.9968 - val_root_mean_squared_error: 17.3204\n",
      "Epoch 47/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4433.7837 - root_mean_squared_error: 66.5867 - val_loss: 1780.9803 - val_root_mean_squared_error: 42.2017\n",
      "Epoch 48/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4317.0752 - root_mean_squared_error: 65.7045 - val_loss: 221.7936 - val_root_mean_squared_error: 14.8927\n",
      "Epoch 49/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4183.3823 - root_mean_squared_error: 64.6791 - val_loss: 407.2661 - val_root_mean_squared_error: 20.1808\n",
      "Epoch 50/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3978.1326 - root_mean_squared_error: 63.0724 - val_loss: 239.4032 - val_root_mean_squared_error: 15.4727\n",
      "Epoch 51/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3839.1726 - root_mean_squared_error: 61.9611 - val_loss: 793.8634 - val_root_mean_squared_error: 28.1756\n",
      "Epoch 52/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3849.4919 - root_mean_squared_error: 62.0443 - val_loss: 338.1635 - val_root_mean_squared_error: 18.3892\n",
      "Epoch 53/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 3621.6167 - root_mean_squared_error: 60.1799 - val_loss: 308.6773 - val_root_mean_squared_error: 17.5692\n",
      "Epoch 54/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3523.2805 - root_mean_squared_error: 59.3572 - val_loss: 206.8929 - val_root_mean_squared_error: 14.3838\n",
      "Epoch 55/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 3429.9602 - root_mean_squared_error: 58.5659 - val_loss: 246.3714 - val_root_mean_squared_error: 15.6962\n",
      "Epoch 56/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 3199.3652 - root_mean_squared_error: 56.5629 - val_loss: 212.1628 - val_root_mean_squared_error: 14.5658\n",
      "Epoch 57/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3140.8547 - root_mean_squared_error: 56.0433 - val_loss: 189.6954 - val_root_mean_squared_error: 13.7730\n",
      "Epoch 58/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2987.6763 - root_mean_squared_error: 54.6596 - val_loss: 285.5228 - val_root_mean_squared_error: 16.8974\n",
      "Epoch 59/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2901.1548 - root_mean_squared_error: 53.8624 - val_loss: 211.7209 - val_root_mean_squared_error: 14.5506\n",
      "Epoch 60/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2706.0442 - root_mean_squared_error: 52.0197 - val_loss: 381.8816 - val_root_mean_squared_error: 19.5418\n",
      "Epoch 61/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2623.9297 - root_mean_squared_error: 51.2243 - val_loss: 275.9868 - val_root_mean_squared_error: 16.6129\n",
      "Epoch 62/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2479.8047 - root_mean_squared_error: 49.7976 - val_loss: 499.4515 - val_root_mean_squared_error: 22.3484\n",
      "Epoch 63/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2369.4680 - root_mean_squared_error: 48.6772 - val_loss: 420.5090 - val_root_mean_squared_error: 20.5063\n",
      "Epoch 64/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2286.5874 - root_mean_squared_error: 47.8183 - val_loss: 486.3570 - val_root_mean_squared_error: 22.0535\n",
      "Epoch 65/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2150.8586 - root_mean_squared_error: 46.3773 - val_loss: 280.4799 - val_root_mean_squared_error: 16.7475\n",
      "Epoch 66/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2056.5596 - root_mean_squared_error: 45.3493 - val_loss: 199.3815 - val_root_mean_squared_error: 14.1202\n",
      "Epoch 67/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1883.5148 - root_mean_squared_error: 43.3995 - val_loss: 202.2251 - val_root_mean_squared_error: 14.2206\n",
      "Epoch 68/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1812.8118 - root_mean_squared_error: 42.5771 - val_loss: 148.2683 - val_root_mean_squared_error: 12.1765\n",
      "Epoch 69/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1703.8579 - root_mean_squared_error: 41.2778 - val_loss: 178.7400 - val_root_mean_squared_error: 13.3694\n",
      "Epoch 70/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1613.2808 - root_mean_squared_error: 40.1657 - val_loss: 193.7659 - val_root_mean_squared_error: 13.9200\n",
      "Epoch 71/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1510.8719 - root_mean_squared_error: 38.8699 - val_loss: 258.8167 - val_root_mean_squared_error: 16.0878\n",
      "Epoch 72/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1402.4697 - root_mean_squared_error: 37.4496 - val_loss: 437.7133 - val_root_mean_squared_error: 20.9216\n",
      "Epoch 73/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1319.9338 - root_mean_squared_error: 36.3309 - val_loss: 140.5674 - val_root_mean_squared_error: 11.8561\n",
      "Epoch 74/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1219.4823 - root_mean_squared_error: 34.9211 - val_loss: 170.0535 - val_root_mean_squared_error: 13.0405\n",
      "Epoch 75/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1121.3326 - root_mean_squared_error: 33.4863 - val_loss: 128.9112 - val_root_mean_squared_error: 11.3539\n",
      "Epoch 76/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1046.2509 - root_mean_squared_error: 32.3458 - val_loss: 129.0502 - val_root_mean_squared_error: 11.3600\n",
      "Epoch 77/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 957.1234 - root_mean_squared_error: 30.9374 - val_loss: 112.9781 - val_root_mean_squared_error: 10.6291\n",
      "Epoch 78/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 879.7872 - root_mean_squared_error: 29.6612 - val_loss: 169.6945 - val_root_mean_squared_error: 13.0267\n",
      "Epoch 79/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 842.3547 - root_mean_squared_error: 29.0233 - val_loss: 143.0339 - val_root_mean_squared_error: 11.9597\n",
      "Epoch 80/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 750.7850 - root_mean_squared_error: 27.4005 - val_loss: 155.5376 - val_root_mean_squared_error: 12.4715\n",
      "Epoch 81/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 704.9158 - root_mean_squared_error: 26.5503 - val_loss: 371.7332 - val_root_mean_squared_error: 19.2804\n",
      "Epoch 82/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 637.2809 - root_mean_squared_error: 25.2444 - val_loss: 129.0858 - val_root_mean_squared_error: 11.3616\n",
      "Epoch 83/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 567.0496 - root_mean_squared_error: 23.8128 - val_loss: 116.8976 - val_root_mean_squared_error: 10.8119\n",
      "Epoch 84/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 530.6227 - root_mean_squared_error: 23.0352 - val_loss: 163.0838 - val_root_mean_squared_error: 12.7704\n",
      "Epoch 85/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 472.7666 - root_mean_squared_error: 21.7432 - val_loss: 110.2815 - val_root_mean_squared_error: 10.5015\n",
      "Epoch 86/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 426.4674 - root_mean_squared_error: 20.6511 - val_loss: 108.8812 - val_root_mean_squared_error: 10.4346\n",
      "Epoch 87/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 390.8387 - root_mean_squared_error: 19.7696 - val_loss: 102.0710 - val_root_mean_squared_error: 10.1030\n",
      "Epoch 88/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 342.5398 - root_mean_squared_error: 18.5078 - val_loss: 124.0730 - val_root_mean_squared_error: 11.1388\n",
      "Epoch 89/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 309.7608 - root_mean_squared_error: 17.6000 - val_loss: 102.0935 - val_root_mean_squared_error: 10.1041\n",
      "Epoch 90/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 281.2473 - root_mean_squared_error: 16.7704 - val_loss: 107.2981 - val_root_mean_squared_error: 10.3585\n",
      "Epoch 91/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 252.5935 - root_mean_squared_error: 15.8932 - val_loss: 187.1766 - val_root_mean_squared_error: 13.6812\n",
      "Epoch 92/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 228.9495 - root_mean_squared_error: 15.1311 - val_loss: 110.7459 - val_root_mean_squared_error: 10.5236\n",
      "Epoch 93/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 205.8482 - root_mean_squared_error: 14.3474 - val_loss: 101.6447 - val_root_mean_squared_error: 10.0819\n",
      "Epoch 94/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 190.4712 - root_mean_squared_error: 13.8011 - val_loss: 97.8791 - val_root_mean_squared_error: 9.8934\n",
      "Epoch 95/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 172.6317 - root_mean_squared_error: 13.1389 - val_loss: 95.0138 - val_root_mean_squared_error: 9.7475\n",
      "Epoch 96/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 161.7378 - root_mean_squared_error: 12.7176 - val_loss: 96.9069 - val_root_mean_squared_error: 9.8441\n",
      "Epoch 97/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 145.7051 - root_mean_squared_error: 12.0708 - val_loss: 100.2980 - val_root_mean_squared_error: 10.0149\n",
      "Epoch 98/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 140.0540 - root_mean_squared_error: 11.8344 - val_loss: 133.1821 - val_root_mean_squared_error: 11.5405\n",
      "Epoch 99/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 134.5994 - root_mean_squared_error: 11.6017 - val_loss: 123.0822 - val_root_mean_squared_error: 11.0942\n",
      "Epoch 100/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 123.9990 - root_mean_squared_error: 11.1355 - val_loss: 139.7368 - val_root_mean_squared_error: 11.8210\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 136.4507 - root_mean_squared_error: 11.6812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 136.45065307617188, 'root_mean_squared_error': 11.681209564208984}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Red Neuronal 3\n",
    "\n",
    "\n",
    "''' \n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "Es te resultado unicamente escalando\n",
    "{'loss': 113.59896850585938, 'root_mean_squared_error': 10.658281326293945}\n",
    "'''\n",
    "# Build the model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, Y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 1257587.0000 - root_mean_squared_error: 1121.4219 - val_loss: 171255.5312 - val_root_mean_squared_error: 413.8303\n",
      "Epoch 2/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 127195.6172 - root_mean_squared_error: 356.6450 - val_loss: 109215.0312 - val_root_mean_squared_error: 330.4770\n",
      "Epoch 3/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 79846.7812 - root_mean_squared_error: 282.5717 - val_loss: 71911.0547 - val_root_mean_squared_error: 268.1624\n",
      "Epoch 4/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 48562.8359 - root_mean_squared_error: 220.3698 - val_loss: 42085.6172 - val_root_mean_squared_error: 205.1478\n",
      "Epoch 5/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 25933.3477 - root_mean_squared_error: 161.0383 - val_loss: 21830.0605 - val_root_mean_squared_error: 147.7500\n",
      "Epoch 6/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 11393.8369 - root_mean_squared_error: 106.7419 - val_loss: 9521.6357 - val_root_mean_squared_error: 97.5789\n",
      "Epoch 7/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 4154.6040 - root_mean_squared_error: 64.4562 - val_loss: 3643.0566 - val_root_mean_squared_error: 60.3577\n",
      "Epoch 8/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 1648.0090 - root_mean_squared_error: 40.5957 - val_loss: 2187.7654 - val_root_mean_squared_error: 46.7736\n",
      "Epoch 9/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 863.0651 - root_mean_squared_error: 29.3780 - val_loss: 1256.9009 - val_root_mean_squared_error: 35.4528\n",
      "Epoch 10/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 552.8654 - root_mean_squared_error: 23.5131 - val_loss: 848.0384 - val_root_mean_squared_error: 29.1211\n",
      "Epoch 11/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 395.6635 - root_mean_squared_error: 19.8913 - val_loss: 700.5081 - val_root_mean_squared_error: 26.4671\n",
      "Epoch 12/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 318.5688 - root_mean_squared_error: 17.8485 - val_loss: 557.8764 - val_root_mean_squared_error: 23.6194\n",
      "Epoch 13/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 335.0194 - root_mean_squared_error: 18.3035 - val_loss: 443.5453 - val_root_mean_squared_error: 21.0605\n",
      "Epoch 14/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 336.6357 - root_mean_squared_error: 18.3476 - val_loss: 895.4008 - val_root_mean_squared_error: 29.9232\n",
      "Epoch 15/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 333.9564 - root_mean_squared_error: 18.2745 - val_loss: 418.9783 - val_root_mean_squared_error: 20.4690\n",
      "Epoch 16/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 161.2477 - root_mean_squared_error: 12.6983 - val_loss: 455.3140 - val_root_mean_squared_error: 21.3381\n",
      "Epoch 17/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 179.7220 - root_mean_squared_error: 13.4060 - val_loss: 2007.8177 - val_root_mean_squared_error: 44.8087\n",
      "Epoch 18/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 430.4655 - root_mean_squared_error: 20.7477 - val_loss: 285.1447 - val_root_mean_squared_error: 16.8862\n",
      "Epoch 19/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 226.0689 - root_mean_squared_error: 15.0356 - val_loss: 393.6915 - val_root_mean_squared_error: 19.8417\n",
      "Epoch 20/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 183.7809 - root_mean_squared_error: 13.5566 - val_loss: 241.1995 - val_root_mean_squared_error: 15.5306\n",
      "Epoch 21/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 178.0658 - root_mean_squared_error: 13.3441 - val_loss: 308.0613 - val_root_mean_squared_error: 17.5517\n",
      "Epoch 22/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 177.9307 - root_mean_squared_error: 13.3391 - val_loss: 236.7934 - val_root_mean_squared_error: 15.3881\n",
      "Epoch 23/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 217.2986 - root_mean_squared_error: 14.7411 - val_loss: 252.2643 - val_root_mean_squared_error: 15.8828\n",
      "Epoch 24/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 185.4073 - root_mean_squared_error: 13.6164 - val_loss: 216.4033 - val_root_mean_squared_error: 14.7107\n",
      "Epoch 25/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 178.7464 - root_mean_squared_error: 13.3696 - val_loss: 229.8077 - val_root_mean_squared_error: 15.1594\n",
      "Epoch 26/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 179.5726 - root_mean_squared_error: 13.4005 - val_loss: 260.6101 - val_root_mean_squared_error: 16.1434\n",
      "Epoch 27/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 258.7897 - root_mean_squared_error: 16.0869 - val_loss: 217.1535 - val_root_mean_squared_error: 14.7361\n",
      "Epoch 28/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 221.4973 - root_mean_squared_error: 14.8828 - val_loss: 232.2743 - val_root_mean_squared_error: 15.2405\n",
      "Epoch 29/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 191.0657 - root_mean_squared_error: 13.8227 - val_loss: 209.2647 - val_root_mean_squared_error: 14.4660\n",
      "Epoch 30/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 156.9011 - root_mean_squared_error: 12.5260 - val_loss: 180.6308 - val_root_mean_squared_error: 13.4399\n",
      "Epoch 31/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 139.7373 - root_mean_squared_error: 11.8211 - val_loss: 183.2027 - val_root_mean_squared_error: 13.5352\n",
      "Epoch 32/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 201.6824 - root_mean_squared_error: 14.2015 - val_loss: 209.1196 - val_root_mean_squared_error: 14.4610\n",
      "Epoch 33/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 147.7515 - root_mean_squared_error: 12.1553 - val_loss: 181.6503 - val_root_mean_squared_error: 13.4778\n",
      "Epoch 34/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 132.6770 - root_mean_squared_error: 11.5185 - val_loss: 350.0149 - val_root_mean_squared_error: 18.7087\n",
      "Epoch 35/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 161.6235 - root_mean_squared_error: 12.7131 - val_loss: 227.2329 - val_root_mean_squared_error: 15.0742\n",
      "Epoch 36/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 199.0408 - root_mean_squared_error: 14.1082 - val_loss: 200.1997 - val_root_mean_squared_error: 14.1492\n",
      "Epoch 37/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 181.3952 - root_mean_squared_error: 13.4683 - val_loss: 213.7394 - val_root_mean_squared_error: 14.6198\n",
      "Epoch 38/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 314.3247 - root_mean_squared_error: 17.7292 - val_loss: 279.5952 - val_root_mean_squared_error: 16.7211\n",
      "Epoch 39/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 141.9718 - root_mean_squared_error: 11.9152 - val_loss: 292.7780 - val_root_mean_squared_error: 17.1108\n",
      "Epoch 40/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 119.6831 - root_mean_squared_error: 10.9400 - val_loss: 160.4924 - val_root_mean_squared_error: 12.6686\n",
      "Epoch 41/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 198.6111 - root_mean_squared_error: 14.0929 - val_loss: 242.7756 - val_root_mean_squared_error: 15.5813\n",
      "Epoch 42/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 184.8123 - root_mean_squared_error: 13.5946 - val_loss: 201.0758 - val_root_mean_squared_error: 14.1801\n",
      "Epoch 43/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 235.6212 - root_mean_squared_error: 15.3500 - val_loss: 175.4899 - val_root_mean_squared_error: 13.2473\n",
      "Epoch 44/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 137.7088 - root_mean_squared_error: 11.7349 - val_loss: 365.9943 - val_root_mean_squared_error: 19.1310\n",
      "Epoch 45/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 120.8774 - root_mean_squared_error: 10.9944 - val_loss: 230.1950 - val_root_mean_squared_error: 15.1722\n",
      "Epoch 46/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 124.4221 - root_mean_squared_error: 11.1545 - val_loss: 155.3780 - val_root_mean_squared_error: 12.4651\n",
      "Epoch 47/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 211.8447 - root_mean_squared_error: 14.5549 - val_loss: 224.2867 - val_root_mean_squared_error: 14.9762\n",
      "Epoch 48/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 234.7434 - root_mean_squared_error: 15.3213 - val_loss: 188.1395 - val_root_mean_squared_error: 13.7164\n",
      "Epoch 49/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 156.3728 - root_mean_squared_error: 12.5049 - val_loss: 140.7460 - val_root_mean_squared_error: 11.8636\n",
      "Epoch 50/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 117.7265 - root_mean_squared_error: 10.8502 - val_loss: 169.2362 - val_root_mean_squared_error: 13.0091\n",
      "Epoch 51/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 123.1610 - root_mean_squared_error: 11.0978 - val_loss: 137.5338 - val_root_mean_squared_error: 11.7275\n",
      "Epoch 52/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 153.4019 - root_mean_squared_error: 12.3856 - val_loss: 201.3891 - val_root_mean_squared_error: 14.1912\n",
      "Epoch 53/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 162.4441 - root_mean_squared_error: 12.7454 - val_loss: 162.7293 - val_root_mean_squared_error: 12.7565\n",
      "Epoch 54/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 156.6197 - root_mean_squared_error: 12.5148 - val_loss: 142.3364 - val_root_mean_squared_error: 11.9305\n",
      "Epoch 55/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 115.3940 - root_mean_squared_error: 10.7422 - val_loss: 277.6734 - val_root_mean_squared_error: 16.6635\n",
      "Epoch 56/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 132.9873 - root_mean_squared_error: 11.5320 - val_loss: 134.7876 - val_root_mean_squared_error: 11.6098\n",
      "Epoch 57/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 137.9961 - root_mean_squared_error: 11.7472 - val_loss: 160.9682 - val_root_mean_squared_error: 12.6873\n",
      "Epoch 58/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 153.6543 - root_mean_squared_error: 12.3957 - val_loss: 188.1312 - val_root_mean_squared_error: 13.7161\n",
      "Epoch 59/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 139.4564 - root_mean_squared_error: 11.8092 - val_loss: 152.9126 - val_root_mean_squared_error: 12.3658\n",
      "Epoch 60/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 176.6699 - root_mean_squared_error: 13.2917 - val_loss: 164.2840 - val_root_mean_squared_error: 12.8173\n",
      "Epoch 61/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 137.3983 - root_mean_squared_error: 11.7217 - val_loss: 1841.2649 - val_root_mean_squared_error: 42.9100\n",
      "Epoch 62/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 148.7475 - root_mean_squared_error: 12.1962 - val_loss: 164.4909 - val_root_mean_squared_error: 12.8254\n",
      "Epoch 63/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 206.8605 - root_mean_squared_error: 14.3826 - val_loss: 875.0898 - val_root_mean_squared_error: 29.5819\n",
      "Epoch 64/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 139.1416 - root_mean_squared_error: 11.7958 - val_loss: 548.6429 - val_root_mean_squared_error: 23.4231\n",
      "Epoch 65/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 122.0898 - root_mean_squared_error: 11.0494 - val_loss: 161.4956 - val_root_mean_squared_error: 12.7081\n",
      "Epoch 66/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 164.4135 - root_mean_squared_error: 12.8224 - val_loss: 192.7885 - val_root_mean_squared_error: 13.8848\n",
      "Epoch 67/100\n",
      "778/778 [==============================] - 1s 1ms/step - loss: 132.3396 - root_mean_squared_error: 11.5039 - val_loss: 179.8928 - val_root_mean_squared_error: 13.4124\n",
      "Epoch 68/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 148.7095 - root_mean_squared_error: 12.1946 - val_loss: 171.1811 - val_root_mean_squared_error: 13.0836\n",
      "Epoch 69/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 149.3214 - root_mean_squared_error: 12.2197 - val_loss: 153.7428 - val_root_mean_squared_error: 12.3993\n",
      "Epoch 70/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 174.5161 - root_mean_squared_error: 13.2105 - val_loss: 161.2514 - val_root_mean_squared_error: 12.6985\n",
      "Epoch 71/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 172.2544 - root_mean_squared_error: 13.1246 - val_loss: 190.1691 - val_root_mean_squared_error: 13.7902\n",
      "Epoch 72/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 106.3143 - root_mean_squared_error: 10.3109 - val_loss: 184.9532 - val_root_mean_squared_error: 13.5997\n",
      "Epoch 73/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 105.9256 - root_mean_squared_error: 10.2920 - val_loss: 152.0789 - val_root_mean_squared_error: 12.3320\n",
      "Epoch 74/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 161.1666 - root_mean_squared_error: 12.6951 - val_loss: 172.3635 - val_root_mean_squared_error: 13.1287\n",
      "Epoch 75/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 208.8970 - root_mean_squared_error: 14.4533 - val_loss: 181.1375 - val_root_mean_squared_error: 13.4587\n",
      "Epoch 76/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 189.3763 - root_mean_squared_error: 13.7614 - val_loss: 149.4305 - val_root_mean_squared_error: 12.2242\n",
      "Epoch 77/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 225.9803 - root_mean_squared_error: 15.0326 - val_loss: 159.0831 - val_root_mean_squared_error: 12.6128\n",
      "Epoch 78/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 98.9864 - root_mean_squared_error: 9.9492 - val_loss: 143.3844 - val_root_mean_squared_error: 11.9743\n",
      "Epoch 79/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 101.7608 - root_mean_squared_error: 10.0877 - val_loss: 144.0482 - val_root_mean_squared_error: 12.0020\n",
      "Epoch 80/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 107.6109 - root_mean_squared_error: 10.3736 - val_loss: 144.7840 - val_root_mean_squared_error: 12.0326\n",
      "Epoch 81/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 127.5456 - root_mean_squared_error: 11.2936 - val_loss: 165.1084 - val_root_mean_squared_error: 12.8495\n",
      "Epoch 82/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 195.1488 - root_mean_squared_error: 13.9696 - val_loss: 224.6392 - val_root_mean_squared_error: 14.9880\n",
      "Epoch 83/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 225.8025 - root_mean_squared_error: 15.0267 - val_loss: 155.1842 - val_root_mean_squared_error: 12.4573\n",
      "Epoch 84/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 111.4243 - root_mean_squared_error: 10.5558 - val_loss: 145.8415 - val_root_mean_squared_error: 12.0765\n",
      "Epoch 85/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 137.1112 - root_mean_squared_error: 11.7094 - val_loss: 145.5449 - val_root_mean_squared_error: 12.0642\n",
      "Epoch 86/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 147.0390 - root_mean_squared_error: 12.1260 - val_loss: 124.9225 - val_root_mean_squared_error: 11.1769\n",
      "Epoch 87/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 117.8712 - root_mean_squared_error: 10.8568 - val_loss: 134.8806 - val_root_mean_squared_error: 11.6138\n",
      "Epoch 88/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 157.8296 - root_mean_squared_error: 12.5630 - val_loss: 133.9457 - val_root_mean_squared_error: 11.5735\n",
      "Epoch 89/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 105.4979 - root_mean_squared_error: 10.2712 - val_loss: 1250.1648 - val_root_mean_squared_error: 35.3577\n",
      "Epoch 90/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 143.1896 - root_mean_squared_error: 11.9662 - val_loss: 131.5611 - val_root_mean_squared_error: 11.4700\n",
      "Epoch 91/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 176.1956 - root_mean_squared_error: 13.2739 - val_loss: 130.7315 - val_root_mean_squared_error: 11.4338\n",
      "Epoch 92/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 126.7723 - root_mean_squared_error: 11.2593 - val_loss: 134.1479 - val_root_mean_squared_error: 11.5822\n",
      "Epoch 93/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 142.3490 - root_mean_squared_error: 11.9310 - val_loss: 136.6721 - val_root_mean_squared_error: 11.6907\n",
      "Epoch 94/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 109.3510 - root_mean_squared_error: 10.4571 - val_loss: 216.5986 - val_root_mean_squared_error: 14.7173\n",
      "Epoch 95/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 116.7109 - root_mean_squared_error: 10.8033 - val_loss: 138.4771 - val_root_mean_squared_error: 11.7676\n",
      "Epoch 96/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 111.8376 - root_mean_squared_error: 10.5753 - val_loss: 145.6978 - val_root_mean_squared_error: 12.0705\n",
      "Epoch 97/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 106.2881 - root_mean_squared_error: 10.3096 - val_loss: 133.2937 - val_root_mean_squared_error: 11.5453\n",
      "Epoch 98/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 136.0451 - root_mean_squared_error: 11.6638 - val_loss: 159.1949 - val_root_mean_squared_error: 12.6172\n",
      "Epoch 99/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 143.9848 - root_mean_squared_error: 11.9994 - val_loss: 120.3446 - val_root_mean_squared_error: 10.9702\n",
      "Epoch 100/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 119.6076 - root_mean_squared_error: 10.9365 - val_loss: 123.8938 - val_root_mean_squared_error: 11.1308\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 104.1071 - root_mean_squared_error: 10.2033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 104.10710144042969, 'root_mean_squared_error': 10.203289031982422}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar PCA para reducir la dimensionalidad\n",
    "pca = PCA(n_components=50)  # Elegir el número de componentes principales deseado\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_pca.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pca, Y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test_pca, Y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "487/487 [==============================] - 1s 1ms/step - loss: 113.5990 - root_mean_squared_error: 10.6583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 113.59896850585938, 'root_mean_squared_error': 10.658281326293945}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
       "       'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40',\n",
       "       'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50',\n",
       "       'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60',\n",
       "       'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70',\n",
       "       'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80',\n",
       "       'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargue datos Test\n",
    "test_data = pd.read_csv('testReg.csv')\n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Para Cargue Kaggle \n",
    "\n",
    "# Preprocesar los datos de prueba (escalar las características)\n",
    "X_test_scaled = scaler.transform(test_data.drop('ID', axis=1).values)\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Redondear las predicciones a números enteros\n",
    "rounded_predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Crear un DataFrame con las columnas 'ID' y 'Y' utilizando las predicciones redondeadas\n",
    "submission_df = pd.DataFrame({'ID': test_data['ID'], 'Y': rounded_predictions})\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
