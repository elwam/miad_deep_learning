{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('trainReg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77779, 92)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77779 entries, 0 to 77778\n",
      "Data columns (total 92 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ID      77779 non-null  int64  \n",
      " 1   Y       77779 non-null  int64  \n",
      " 2   V1      77779 non-null  float64\n",
      " 3   V2      77779 non-null  float64\n",
      " 4   V3      77779 non-null  int64  \n",
      " 5   V4      77779 non-null  float64\n",
      " 6   V5      77779 non-null  float64\n",
      " 7   V6      77779 non-null  float64\n",
      " 8   V7      77779 non-null  float64\n",
      " 9   V8      77779 non-null  float64\n",
      " 10  V9      77779 non-null  float64\n",
      " 11  V10     77779 non-null  float64\n",
      " 12  V11     77779 non-null  float64\n",
      " 13  V12     77779 non-null  float64\n",
      " 14  V13     77779 non-null  float64\n",
      " 15  V14     77779 non-null  float64\n",
      " 16  V15     77779 non-null  float64\n",
      " 17  V16     77779 non-null  float64\n",
      " 18  V17     77779 non-null  float64\n",
      " 19  V18     77779 non-null  float64\n",
      " 20  V19     77779 non-null  float64\n",
      " 21  V20     77779 non-null  float64\n",
      " 22  V21     77779 non-null  float64\n",
      " 23  V22     77779 non-null  float64\n",
      " 24  V23     77779 non-null  float64\n",
      " 25  V24     77779 non-null  float64\n",
      " 26  V25     77779 non-null  float64\n",
      " 27  V26     77779 non-null  float64\n",
      " 28  V27     77779 non-null  float64\n",
      " 29  V28     77779 non-null  float64\n",
      " 30  V29     77779 non-null  float64\n",
      " 31  V30     77779 non-null  float64\n",
      " 32  V31     77779 non-null  float64\n",
      " 33  V32     77779 non-null  float64\n",
      " 34  V33     77779 non-null  float64\n",
      " 35  V34     77779 non-null  float64\n",
      " 36  V35     77779 non-null  float64\n",
      " 37  V36     77779 non-null  float64\n",
      " 38  V37     77779 non-null  float64\n",
      " 39  V38     77779 non-null  float64\n",
      " 40  V39     77779 non-null  float64\n",
      " 41  V40     77779 non-null  float64\n",
      " 42  V41     77779 non-null  float64\n",
      " 43  V42     77779 non-null  float64\n",
      " 44  V43     77779 non-null  float64\n",
      " 45  V44     77779 non-null  float64\n",
      " 46  V45     77779 non-null  float64\n",
      " 47  V46     77779 non-null  float64\n",
      " 48  V47     77779 non-null  float64\n",
      " 49  V48     77779 non-null  float64\n",
      " 50  V49     77779 non-null  float64\n",
      " 51  V50     77779 non-null  float64\n",
      " 52  V51     77779 non-null  float64\n",
      " 53  V52     77779 non-null  float64\n",
      " 54  V53     77779 non-null  float64\n",
      " 55  V54     77779 non-null  float64\n",
      " 56  V55     77779 non-null  float64\n",
      " 57  V56     77779 non-null  float64\n",
      " 58  V57     77779 non-null  float64\n",
      " 59  V58     77779 non-null  float64\n",
      " 60  V59     77779 non-null  float64\n",
      " 61  V60     77779 non-null  float64\n",
      " 62  V61     77779 non-null  float64\n",
      " 63  V62     77779 non-null  float64\n",
      " 64  V63     77779 non-null  float64\n",
      " 65  V64     77779 non-null  float64\n",
      " 66  V65     77779 non-null  float64\n",
      " 67  V66     77779 non-null  float64\n",
      " 68  V67     77779 non-null  float64\n",
      " 69  V68     77779 non-null  float64\n",
      " 70  V69     77779 non-null  float64\n",
      " 71  V70     77779 non-null  float64\n",
      " 72  V71     77779 non-null  float64\n",
      " 73  V72     77779 non-null  float64\n",
      " 74  V73     77779 non-null  float64\n",
      " 75  V74     77779 non-null  float64\n",
      " 76  V75     77779 non-null  float64\n",
      " 77  V76     77779 non-null  float64\n",
      " 78  V77     77779 non-null  float64\n",
      " 79  V78     77779 non-null  float64\n",
      " 80  V79     77779 non-null  float64\n",
      " 81  V80     77779 non-null  float64\n",
      " 82  V81     77779 non-null  float64\n",
      " 83  V82     77779 non-null  float64\n",
      " 84  V83     77779 non-null  float64\n",
      " 85  V84     77779 non-null  float64\n",
      " 86  V85     77779 non-null  float64\n",
      " 87  V86     77779 non-null  float64\n",
      " 88  V87     77779 non-null  float64\n",
      " 89  V88     77779 non-null  float64\n",
      " 90  V89     77779 non-null  float64\n",
      " 91  V90     77779 non-null  float64\n",
      "dtypes: float64(89), int64(3)\n",
      "memory usage: 54.6 MB\n",
      "None\n",
      "                 ID             Y            V1            V2       V3  \\\n",
      "count  77779.000000  77779.000000  77779.000000  77779.000000  77779.0   \n",
      "mean   48244.238342   2002.308129     43.425185     -0.136720      0.0   \n",
      "std    27846.283673     10.811038      6.128869      4.370466      0.0   \n",
      "min        1.000000   1926.000000      4.836880    -69.680870      0.0   \n",
      "25%    24079.500000   1998.000000     40.060315     -2.612435      0.0   \n",
      "50%    48357.000000   2006.000000     44.323850     -0.063000      0.0   \n",
      "75%    72340.500000   2010.000000     47.900080      2.465950      0.0   \n",
      "max    96435.000000   2014.000000     60.034010     23.815260      0.0   \n",
      "\n",
      "                 V4            V5            V6            V7            V8  \\\n",
      "count  77779.000000  77779.000000  77779.000000  77779.000000  77779.000000   \n",
      "mean       3.755313     -2.339768     -1.643095     -6.814997     -9.587264   \n",
      "std       17.609183     14.483975      7.898574     22.980515     12.911914   \n",
      "min     -165.221610   -121.475340    -72.503850   -152.407550    -70.693420   \n",
      "25%       -7.016240    -10.685075     -6.300690    -21.265305    -18.583065   \n",
      "50%        2.022100     -2.054560     -1.586240     -6.307610    -11.238330   \n",
      "75%       12.776450      6.423900      3.077055      7.617995     -2.329330   \n",
      "max      274.658580    160.815220     68.447960    262.068870    112.971410   \n",
      "\n",
      "       ...           V81           V82           V83           V84  \\\n",
      "count  ...  77779.000000  77779.000000  77779.000000  77779.000000   \n",
      "mean   ...     15.717215    -71.733008     41.679287     37.816353   \n",
      "std    ...     32.211995    176.893351    123.523393     95.335357   \n",
      "min    ...   -424.517570  -4402.376440  -1733.722110  -1848.702260   \n",
      "25%    ...     -1.968265   -136.511095    -21.467975     -4.604295   \n",
      "50%    ...      9.079980    -51.322570     28.217560     33.417370   \n",
      "75%    ...     26.211700     13.999870     89.190475     77.216175   \n",
      "max    ...    840.973380   2147.942140   3210.701700   1482.642140   \n",
      "\n",
      "                V85           V86           V87           V88           V89  \\\n",
      "count  77779.000000  77779.000000  77779.000000  77779.000000  77779.000000   \n",
      "mean       0.328213     17.575097    -25.628857      4.463484     18.664885   \n",
      "std       16.272689    115.243644    173.310304     13.526414    186.690183   \n",
      "min     -238.386730  -3168.924570  -4319.992320   -236.039260  -7458.378150   \n",
      "25%       -6.702370    -31.569390   -100.668480     -2.569360    -60.121980   \n",
      "50%        0.788980     15.237360    -21.581640      3.136900      5.941490   \n",
      "75%        8.354270     67.361475     51.333150     10.002145     84.389125   \n",
      "max      199.121500   2144.103910   2833.608950    275.353660   5289.111380   \n",
      "\n",
      "                V90  \n",
      "count  77779.000000  \n",
      "mean       1.240194  \n",
      "std       22.379654  \n",
      "min     -281.150600  \n",
      "25%       -8.900120  \n",
      "50%       -0.095340  \n",
      "75%        9.520700  \n",
      "max      600.766240  \n",
      "\n",
      "[8 rows x 92 columns]\n",
      "Index(['ID', 'Y', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
      "       'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40',\n",
      "       'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50',\n",
      "       'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60',\n",
      "       'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70',\n",
      "       'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80',\n",
      "       'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V81</th>\n",
       "      <th>V82</th>\n",
       "      <th>V83</th>\n",
       "      <th>V84</th>\n",
       "      <th>V85</th>\n",
       "      <th>V86</th>\n",
       "      <th>V87</th>\n",
       "      <th>V88</th>\n",
       "      <th>V89</th>\n",
       "      <th>V90</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>44.81144</td>\n",
       "      <td>0.83826</td>\n",
       "      <td>0</td>\n",
       "      <td>7.91314</td>\n",
       "      <td>10.94148</td>\n",
       "      <td>-0.04547</td>\n",
       "      <td>-15.16332</td>\n",
       "      <td>-10.47324</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.44873</td>\n",
       "      <td>-230.30484</td>\n",
       "      <td>-40.94698</td>\n",
       "      <td>48.20025</td>\n",
       "      <td>-0.28694</td>\n",
       "      <td>155.76251</td>\n",
       "      <td>-56.23579</td>\n",
       "      <td>13.62599</td>\n",
       "      <td>123.92018</td>\n",
       "      <td>10.02845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1998</td>\n",
       "      <td>41.99180</td>\n",
       "      <td>7.99976</td>\n",
       "      <td>0</td>\n",
       "      <td>64.26707</td>\n",
       "      <td>16.54115</td>\n",
       "      <td>-9.28737</td>\n",
       "      <td>-40.73524</td>\n",
       "      <td>33.60440</td>\n",
       "      <td>...</td>\n",
       "      <td>18.68972</td>\n",
       "      <td>-44.06062</td>\n",
       "      <td>52.37792</td>\n",
       "      <td>81.36093</td>\n",
       "      <td>-14.81111</td>\n",
       "      <td>151.66273</td>\n",
       "      <td>-120.61213</td>\n",
       "      <td>10.57519</td>\n",
       "      <td>-3.21078</td>\n",
       "      <td>-1.07438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1998</td>\n",
       "      <td>42.19196</td>\n",
       "      <td>2.23111</td>\n",
       "      <td>0</td>\n",
       "      <td>65.07719</td>\n",
       "      <td>24.99746</td>\n",
       "      <td>1.76100</td>\n",
       "      <td>6.66573</td>\n",
       "      <td>3.45778</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.69878</td>\n",
       "      <td>-118.95712</td>\n",
       "      <td>54.15529</td>\n",
       "      <td>-23.32168</td>\n",
       "      <td>-9.65067</td>\n",
       "      <td>-83.83055</td>\n",
       "      <td>-141.17594</td>\n",
       "      <td>7.33084</td>\n",
       "      <td>-275.69714</td>\n",
       "      <td>2.35522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1998</td>\n",
       "      <td>39.28634</td>\n",
       "      <td>-1.85716</td>\n",
       "      <td>0</td>\n",
       "      <td>91.04190</td>\n",
       "      <td>9.08333</td>\n",
       "      <td>0.08502</td>\n",
       "      <td>-5.59216</td>\n",
       "      <td>65.62463</td>\n",
       "      <td>...</td>\n",
       "      <td>20.89044</td>\n",
       "      <td>-18.53135</td>\n",
       "      <td>176.09769</td>\n",
       "      <td>351.33669</td>\n",
       "      <td>3.44682</td>\n",
       "      <td>121.69156</td>\n",
       "      <td>-270.43989</td>\n",
       "      <td>12.51659</td>\n",
       "      <td>-140.88884</td>\n",
       "      <td>-0.23476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1998</td>\n",
       "      <td>40.36025</td>\n",
       "      <td>2.94918</td>\n",
       "      <td>0</td>\n",
       "      <td>53.83723</td>\n",
       "      <td>13.71369</td>\n",
       "      <td>-8.21964</td>\n",
       "      <td>-40.21636</td>\n",
       "      <td>21.22366</td>\n",
       "      <td>...</td>\n",
       "      <td>19.91979</td>\n",
       "      <td>34.59026</td>\n",
       "      <td>-69.83720</td>\n",
       "      <td>102.31946</td>\n",
       "      <td>8.08807</td>\n",
       "      <td>135.08089</td>\n",
       "      <td>-153.02327</td>\n",
       "      <td>4.09207</td>\n",
       "      <td>-68.33046</td>\n",
       "      <td>-6.19159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID     Y        V1       V2  V3        V4        V5       V6        V7  \\\n",
       "0   1  2013  44.81144  0.83826   0   7.91314  10.94148 -0.04547 -15.16332   \n",
       "1   2  1998  41.99180  7.99976   0  64.26707  16.54115 -9.28737 -40.73524   \n",
       "2   3  1998  42.19196  2.23111   0  65.07719  24.99746  1.76100   6.66573   \n",
       "3   4  1998  39.28634 -1.85716   0  91.04190   9.08333  0.08502  -5.59216   \n",
       "4   5  1998  40.36025  2.94918   0  53.83723  13.71369 -8.21964 -40.21636   \n",
       "\n",
       "         V8  ...       V81        V82        V83        V84       V85  \\\n",
       "0 -10.47324  ...  -8.44873 -230.30484  -40.94698   48.20025  -0.28694   \n",
       "1  33.60440  ...  18.68972  -44.06062   52.37792   81.36093 -14.81111   \n",
       "2   3.45778  ...  -3.69878 -118.95712   54.15529  -23.32168  -9.65067   \n",
       "3  65.62463  ...  20.89044  -18.53135  176.09769  351.33669   3.44682   \n",
       "4  21.22366  ...  19.91979   34.59026  -69.83720  102.31946   8.08807   \n",
       "\n",
       "         V86        V87       V88        V89       V90  \n",
       "0  155.76251  -56.23579  13.62599  123.92018  10.02845  \n",
       "1  151.66273 -120.61213  10.57519   -3.21078  -1.07438  \n",
       "2  -83.83055 -141.17594   7.33084 -275.69714   2.35522  \n",
       "3  121.69156 -270.43989  12.51659 -140.88884  -0.23476  \n",
       "4  135.08089 -153.02327   4.09207  -68.33046  -6.19159  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "print(data.columns)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'Y', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
      "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
      "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
      "       'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40',\n",
      "       'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50',\n",
      "       'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60',\n",
      "       'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70',\n",
      "       'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80',\n",
      "       'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\seaborn\\_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datos_principales = data[['Y', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10','V11', 'V12']]\n",
    "\n",
    "# Visualizar la distribuciÃ³n de la variable objetivo (AÃ±o)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(datos_principales['Y'], bins=30, kde=True)\n",
    "plt.title('DistribuciÃ³n de AÃ±o de Lanzamiento')\n",
    "plt.xlabel('AÃ±o')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.show()\n",
    "\n",
    "# Visualizar la correlaciÃ³n entre las caracterÃ­sticas\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(datos_principales.corr(), cmap='coolwarm', annot=False)\n",
    "plt.title('Matriz de CorrelaciÃ³n')\n",
    "plt.show()\n",
    "\n",
    "# Visualizar la relaciÃ³n entre algunas caracterÃ­sticas y el aÃ±o de lanzamiento\n",
    "#sns.pairplot(data[['Y', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10','V11', 'V12']], diag_kind='kde')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 474947.9375 - val_loss: 61873.3398\n",
      "Epoch 2/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 115260.1484 - val_loss: 17284.9941\n",
      "Epoch 3/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 92500.3516 - val_loss: 11113.0000\n",
      "Epoch 4/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 87120.7656 - val_loss: 4752.4790\n",
      "Epoch 5/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 84008.7344 - val_loss: 5258.8325\n",
      "Epoch 6/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 82016.4922 - val_loss: 4068.7717\n",
      "Epoch 7/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 80321.0859 - val_loss: 5965.4507\n",
      "Epoch 8/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 80142.5703 - val_loss: 4909.0835\n",
      "Epoch 9/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 79053.8516 - val_loss: 3004.7070\n",
      "Epoch 10/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 79348.3125 - val_loss: 2815.4421\n",
      "Epoch 11/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 78878.3750 - val_loss: 8473.2510\n",
      "Epoch 12/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 77810.9922 - val_loss: 7447.7163\n",
      "Epoch 13/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 77223.7891 - val_loss: 9853.6592\n",
      "Epoch 14/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 77889.9219 - val_loss: 2153.6023\n",
      "Epoch 15/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 76644.5781 - val_loss: 8440.7783\n",
      "Epoch 16/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 76718.2812 - val_loss: 2069.6331\n",
      "Epoch 17/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 75467.1250 - val_loss: 1626.6603\n",
      "Epoch 18/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 73970.6797 - val_loss: 3875.5093\n",
      "Epoch 19/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 74197.5312 - val_loss: 4676.5679\n",
      "Epoch 20/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 74639.2656 - val_loss: 4398.7876\n",
      "Epoch 21/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 73386.5547 - val_loss: 3818.0254\n",
      "Epoch 22/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 72545.1406 - val_loss: 2562.5664\n",
      "Epoch 23/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 71278.1641 - val_loss: 1430.0858\n",
      "Epoch 24/50\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 71513.6641 - val_loss: 4616.6001\n",
      "Epoch 25/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 70246.9688 - val_loss: 7014.8149\n",
      "Epoch 26/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 70908.6562 - val_loss: 3111.1050\n",
      "Epoch 27/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 69376.0859 - val_loss: 5154.5161\n",
      "Epoch 28/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 69504.2578 - val_loss: 644.5491\n",
      "Epoch 29/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 69067.8359 - val_loss: 617.0854\n",
      "Epoch 30/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 67844.1172 - val_loss: 8219.7871\n",
      "Epoch 31/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 67539.5859 - val_loss: 1704.4988\n",
      "Epoch 32/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 67026.3750 - val_loss: 1379.4226\n",
      "Epoch 33/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 66484.9141 - val_loss: 5395.9961\n",
      "Epoch 34/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 67247.7812 - val_loss: 4673.7026\n",
      "Epoch 35/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 66671.0781 - val_loss: 2304.2241\n",
      "Epoch 36/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 65882.0859 - val_loss: 1631.5922\n",
      "Epoch 37/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 65363.8867 - val_loss: 5740.5869\n",
      "Epoch 38/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 64683.7109 - val_loss: 9992.6924\n",
      "Epoch 39/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 65031.3086 - val_loss: 533.3749\n",
      "Epoch 40/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 64705.5039 - val_loss: 1883.0112\n",
      "Epoch 41/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 64356.9336 - val_loss: 966.2379\n",
      "Epoch 42/50\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 63908.8398 - val_loss: 2127.7312\n",
      "Epoch 43/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 63858.6523 - val_loss: 929.0692\n",
      "Epoch 44/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62785.9648 - val_loss: 575.8995\n",
      "Epoch 45/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62363.4023 - val_loss: 2724.0161\n",
      "Epoch 46/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62610.3398 - val_loss: 509.0727\n",
      "Epoch 47/50\n",
      "1750/1750 [==============================] - 4s 2ms/step - loss: 61720.9414 - val_loss: 1372.4093\n",
      "Epoch 48/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 62349.9414 - val_loss: 579.4811\n",
      "Epoch 49/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 60654.0781 - val_loss: 1141.4034\n",
      "Epoch 50/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 61306.8906 - val_loss: 835.7725\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 846.7103\n",
      "Loss en el conjunto de prueba: 846.7102661132812\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en caracterÃ­sticas (X) y etiquetas (Y)\n",
    "X = data.drop(['ID', 'Y'], axis=1).values\n",
    "Y = data['Y'].values\n",
    "\n",
    "# Escalar las caracterÃ­sticas para mejorar el rendimiento del modelo\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construir el modelo de red neuronal\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_split=0.1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss = model.evaluate(X_test, Y_test)\n",
    "print(\"Loss en el conjunto de prueba:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 600785.5000 - val_loss: 97696.8828 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 90038.8672 - val_loss: 27436.4336 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 48270.4648 - val_loss: 9375.0361 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 36954.2852 - val_loss: 4171.8398 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 33534.0664 - val_loss: 2560.3477 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 32160.3809 - val_loss: 2661.2498 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 30772.3809 - val_loss: 1690.9557 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 30793.3770 - val_loss: 1519.0140 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 30362.2559 - val_loss: 1338.0867 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29982.6387 - val_loss: 1544.0146 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 29851.7422 - val_loss: 1316.2700 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29768.8906 - val_loss: 1312.8149 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29231.4668 - val_loss: 1357.1467 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 29056.9531 - val_loss: 1989.8628 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29123.7051 - val_loss: 1643.7095 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29153.1289 - val_loss: 1643.3069 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29045.9102 - val_loss: 1243.8400 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29353.3027 - val_loss: 1265.0123 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28728.7930 - val_loss: 1068.7877 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 29019.5859 - val_loss: 1284.8647 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 28336.1309 - val_loss: 1422.1992 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 28721.5156 - val_loss: 1225.1775 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28370.4648 - val_loss: 603.1976 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28162.9316 - val_loss: 2192.0381 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28309.9238 - val_loss: 1421.9156 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28343.5996 - val_loss: 1016.8364 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 28178.9746 - val_loss: 1733.4520 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27962.7598 - val_loss: 657.0676 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27543.5879 - val_loss: 559.0237 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27109.5820 - val_loss: 469.5639 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27206.4043 - val_loss: 412.9561 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27160.2539 - val_loss: 586.2923 - lr: 2.0000e-04\n",
      "Epoch 33/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26895.7188 - val_loss: 479.3074 - lr: 2.0000e-04\n",
      "Epoch 34/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26922.4023 - val_loss: 536.3222 - lr: 2.0000e-04\n",
      "Epoch 35/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26876.1895 - val_loss: 460.2358 - lr: 2.0000e-04\n",
      "Epoch 36/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26997.7441 - val_loss: 503.3688 - lr: 2.0000e-04\n",
      "Epoch 37/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26870.1836 - val_loss: 276.3347 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26934.0820 - val_loss: 491.7870 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 27089.4219 - val_loss: 374.4857 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26820.9141 - val_loss: 201.7317 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26776.4395 - val_loss: 315.9775 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26954.3086 - val_loss: 341.7509 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26772.8496 - val_loss: 214.0721 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26852.5684 - val_loss: 272.4501 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26811.6113 - val_loss: 250.2004 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26631.4180 - val_loss: 272.0569 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26700.5371 - val_loss: 406.7640 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26553.5293 - val_loss: 405.7386 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26915.3945 - val_loss: 361.1223 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 26759.5566 - val_loss: 387.4381 - lr: 1.0000e-04\n",
      "487/487 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean_squared_error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Calcular el RMSE en el conjunto de datos de prueba\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m rmse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(mean_squared_error(Y_test, predictions))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE en el conjunto de prueba:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean_squared_error' is not defined"
     ]
    }
   ],
   "source": [
    "# Red 2 \n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# Definir el modelo\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# AÃ±adir reducciÃ³n de la tasa de aprendizaje en meseta\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, Y_train, batch_size=32, epochs=50, validation_split=0.1, callbacks=[reduce_lr])\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE en el conjunto de prueba: 19.951228276989834\n"
     ]
    }
   ],
   "source": [
    "# Calcular el RMSE en el conjunto de datos de prueba\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 1118700.8750 - root_mean_squared_error: 1057.6865 - val_loss: 247950.2812 - val_root_mean_squared_error: 497.9461\n",
      "Epoch 2/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 179927.5938 - root_mean_squared_error: 424.1787 - val_loss: 122805.6719 - val_root_mean_squared_error: 350.4364\n",
      "Epoch 3/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 97720.4219 - root_mean_squared_error: 312.6027 - val_loss: 65685.0156 - val_root_mean_squared_error: 256.2909\n",
      "Epoch 4/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 55538.1719 - root_mean_squared_error: 235.6654 - val_loss: 32725.0547 - val_root_mean_squared_error: 180.9007\n",
      "Epoch 5/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 31415.9238 - root_mean_squared_error: 177.2454 - val_loss: 15287.2031 - val_root_mean_squared_error: 123.6414\n",
      "Epoch 6/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 20381.7754 - root_mean_squared_error: 142.7648 - val_loss: 8050.4966 - val_root_mean_squared_error: 89.7246\n",
      "Epoch 7/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 15824.4814 - root_mean_squared_error: 125.7954 - val_loss: 4475.0005 - val_root_mean_squared_error: 66.8954\n",
      "Epoch 8/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 13239.4111 - root_mean_squared_error: 115.0626 - val_loss: 3652.4185 - val_root_mean_squared_error: 60.4352\n",
      "Epoch 9/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 11868.3623 - root_mean_squared_error: 108.9420 - val_loss: 2899.7188 - val_root_mean_squared_error: 53.8490\n",
      "Epoch 10/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 11004.0596 - root_mean_squared_error: 104.9002 - val_loss: 1919.8907 - val_root_mean_squared_error: 43.8166\n",
      "Epoch 11/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 10192.4541 - root_mean_squared_error: 100.9577 - val_loss: 1935.3912 - val_root_mean_squared_error: 43.9931\n",
      "Epoch 12/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 9600.1055 - root_mean_squared_error: 97.9801 - val_loss: 1548.4659 - val_root_mean_squared_error: 39.3506\n",
      "Epoch 13/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 9184.8232 - root_mean_squared_error: 95.8375 - val_loss: 1421.3236 - val_root_mean_squared_error: 37.7004\n",
      "Epoch 14/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8827.3613 - root_mean_squared_error: 93.9540 - val_loss: 1116.6229 - val_root_mean_squared_error: 33.4159\n",
      "Epoch 15/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8438.0547 - root_mean_squared_error: 91.8589 - val_loss: 946.9946 - val_root_mean_squared_error: 30.7733\n",
      "Epoch 16/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8398.1729 - root_mean_squared_error: 91.6415 - val_loss: 725.1652 - val_root_mean_squared_error: 26.9289\n",
      "Epoch 17/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 7963.9033 - root_mean_squared_error: 89.2407 - val_loss: 1106.7396 - val_root_mean_squared_error: 33.2677\n",
      "Epoch 18/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 8022.3867 - root_mean_squared_error: 89.5678 - val_loss: 726.4359 - val_root_mean_squared_error: 26.9525\n",
      "Epoch 19/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7751.2773 - root_mean_squared_error: 88.0413 - val_loss: 1143.7322 - val_root_mean_squared_error: 33.8191\n",
      "Epoch 20/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7706.4209 - root_mean_squared_error: 87.7862 - val_loss: 561.7839 - val_root_mean_squared_error: 23.7020\n",
      "Epoch 21/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7495.1196 - root_mean_squared_error: 86.5744 - val_loss: 683.3547 - val_root_mean_squared_error: 26.1411\n",
      "Epoch 22/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7418.7505 - root_mean_squared_error: 86.1322 - val_loss: 663.6052 - val_root_mean_squared_error: 25.7605\n",
      "Epoch 23/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7293.0801 - root_mean_squared_error: 85.3995 - val_loss: 479.0306 - val_root_mean_squared_error: 21.8868\n",
      "Epoch 24/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7151.0596 - root_mean_squared_error: 84.5639 - val_loss: 1277.8113 - val_root_mean_squared_error: 35.7465\n",
      "Epoch 25/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7211.5034 - root_mean_squared_error: 84.9206 - val_loss: 577.5351 - val_root_mean_squared_error: 24.0320\n",
      "Epoch 26/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 7035.1367 - root_mean_squared_error: 83.8757 - val_loss: 387.6982 - val_root_mean_squared_error: 19.6901\n",
      "Epoch 27/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6712.4766 - root_mean_squared_error: 81.9297 - val_loss: 485.6389 - val_root_mean_squared_error: 22.0372\n",
      "Epoch 28/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6711.5728 - root_mean_squared_error: 81.9242 - val_loss: 362.6979 - val_root_mean_squared_error: 19.0446\n",
      "Epoch 29/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6627.0244 - root_mean_squared_error: 81.4065 - val_loss: 512.6206 - val_root_mean_squared_error: 22.6411\n",
      "Epoch 30/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6446.3120 - root_mean_squared_error: 80.2889 - val_loss: 549.2762 - val_root_mean_squared_error: 23.4366\n",
      "Epoch 31/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6224.2495 - root_mean_squared_error: 78.8939 - val_loss: 1113.1095 - val_root_mean_squared_error: 33.3633\n",
      "Epoch 32/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 6249.7900 - root_mean_squared_error: 79.0556 - val_loss: 750.8727 - val_root_mean_squared_error: 27.4021\n",
      "Epoch 33/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 6138.7812 - root_mean_squared_error: 78.3504 - val_loss: 893.2844 - val_root_mean_squared_error: 29.8879\n",
      "Epoch 34/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5954.4932 - root_mean_squared_error: 77.1654 - val_loss: 528.0327 - val_root_mean_squared_error: 22.9790\n",
      "Epoch 35/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5851.0513 - root_mean_squared_error: 76.4922 - val_loss: 335.4610 - val_root_mean_squared_error: 18.3156\n",
      "Epoch 36/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5816.8970 - root_mean_squared_error: 76.2686 - val_loss: 287.2848 - val_root_mean_squared_error: 16.9495\n",
      "Epoch 37/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5682.5815 - root_mean_squared_error: 75.3829 - val_loss: 405.9785 - val_root_mean_squared_error: 20.1489\n",
      "Epoch 38/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5580.2617 - root_mean_squared_error: 74.7011 - val_loss: 597.1459 - val_root_mean_squared_error: 24.4366\n",
      "Epoch 39/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5398.4805 - root_mean_squared_error: 73.4743 - val_loss: 324.6689 - val_root_mean_squared_error: 18.0186\n",
      "Epoch 40/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5307.9673 - root_mean_squared_error: 72.8558 - val_loss: 370.3709 - val_root_mean_squared_error: 19.2450\n",
      "Epoch 41/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5144.1724 - root_mean_squared_error: 71.7229 - val_loss: 349.2915 - val_root_mean_squared_error: 18.6893\n",
      "Epoch 42/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 5096.8105 - root_mean_squared_error: 71.3920 - val_loss: 567.3909 - val_root_mean_squared_error: 23.8200\n",
      "Epoch 43/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4887.1191 - root_mean_squared_error: 69.9079 - val_loss: 434.1218 - val_root_mean_squared_error: 20.8356\n",
      "Epoch 44/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4794.3945 - root_mean_squared_error: 69.2416 - val_loss: 632.7292 - val_root_mean_squared_error: 25.1541\n",
      "Epoch 45/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4702.1479 - root_mean_squared_error: 68.5722 - val_loss: 610.0547 - val_root_mean_squared_error: 24.6993\n",
      "Epoch 46/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4547.4902 - root_mean_squared_error: 67.4351 - val_loss: 299.9968 - val_root_mean_squared_error: 17.3204\n",
      "Epoch 47/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4433.7837 - root_mean_squared_error: 66.5867 - val_loss: 1780.9803 - val_root_mean_squared_error: 42.2017\n",
      "Epoch 48/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4317.0752 - root_mean_squared_error: 65.7045 - val_loss: 221.7936 - val_root_mean_squared_error: 14.8927\n",
      "Epoch 49/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 4183.3823 - root_mean_squared_error: 64.6791 - val_loss: 407.2661 - val_root_mean_squared_error: 20.1808\n",
      "Epoch 50/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3978.1326 - root_mean_squared_error: 63.0724 - val_loss: 239.4032 - val_root_mean_squared_error: 15.4727\n",
      "Epoch 51/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3839.1726 - root_mean_squared_error: 61.9611 - val_loss: 793.8634 - val_root_mean_squared_error: 28.1756\n",
      "Epoch 52/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3849.4919 - root_mean_squared_error: 62.0443 - val_loss: 338.1635 - val_root_mean_squared_error: 18.3892\n",
      "Epoch 53/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 3621.6167 - root_mean_squared_error: 60.1799 - val_loss: 308.6773 - val_root_mean_squared_error: 17.5692\n",
      "Epoch 54/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3523.2805 - root_mean_squared_error: 59.3572 - val_loss: 206.8929 - val_root_mean_squared_error: 14.3838\n",
      "Epoch 55/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 3429.9602 - root_mean_squared_error: 58.5659 - val_loss: 246.3714 - val_root_mean_squared_error: 15.6962\n",
      "Epoch 56/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 3199.3652 - root_mean_squared_error: 56.5629 - val_loss: 212.1628 - val_root_mean_squared_error: 14.5658\n",
      "Epoch 57/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 3140.8547 - root_mean_squared_error: 56.0433 - val_loss: 189.6954 - val_root_mean_squared_error: 13.7730\n",
      "Epoch 58/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2987.6763 - root_mean_squared_error: 54.6596 - val_loss: 285.5228 - val_root_mean_squared_error: 16.8974\n",
      "Epoch 59/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2901.1548 - root_mean_squared_error: 53.8624 - val_loss: 211.7209 - val_root_mean_squared_error: 14.5506\n",
      "Epoch 60/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2706.0442 - root_mean_squared_error: 52.0197 - val_loss: 381.8816 - val_root_mean_squared_error: 19.5418\n",
      "Epoch 61/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2623.9297 - root_mean_squared_error: 51.2243 - val_loss: 275.9868 - val_root_mean_squared_error: 16.6129\n",
      "Epoch 62/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2479.8047 - root_mean_squared_error: 49.7976 - val_loss: 499.4515 - val_root_mean_squared_error: 22.3484\n",
      "Epoch 63/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2369.4680 - root_mean_squared_error: 48.6772 - val_loss: 420.5090 - val_root_mean_squared_error: 20.5063\n",
      "Epoch 64/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2286.5874 - root_mean_squared_error: 47.8183 - val_loss: 486.3570 - val_root_mean_squared_error: 22.0535\n",
      "Epoch 65/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2150.8586 - root_mean_squared_error: 46.3773 - val_loss: 280.4799 - val_root_mean_squared_error: 16.7475\n",
      "Epoch 66/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 2056.5596 - root_mean_squared_error: 45.3493 - val_loss: 199.3815 - val_root_mean_squared_error: 14.1202\n",
      "Epoch 67/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1883.5148 - root_mean_squared_error: 43.3995 - val_loss: 202.2251 - val_root_mean_squared_error: 14.2206\n",
      "Epoch 68/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1812.8118 - root_mean_squared_error: 42.5771 - val_loss: 148.2683 - val_root_mean_squared_error: 12.1765\n",
      "Epoch 69/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1703.8579 - root_mean_squared_error: 41.2778 - val_loss: 178.7400 - val_root_mean_squared_error: 13.3694\n",
      "Epoch 70/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1613.2808 - root_mean_squared_error: 40.1657 - val_loss: 193.7659 - val_root_mean_squared_error: 13.9200\n",
      "Epoch 71/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1510.8719 - root_mean_squared_error: 38.8699 - val_loss: 258.8167 - val_root_mean_squared_error: 16.0878\n",
      "Epoch 72/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1402.4697 - root_mean_squared_error: 37.4496 - val_loss: 437.7133 - val_root_mean_squared_error: 20.9216\n",
      "Epoch 73/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1319.9338 - root_mean_squared_error: 36.3309 - val_loss: 140.5674 - val_root_mean_squared_error: 11.8561\n",
      "Epoch 74/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1219.4823 - root_mean_squared_error: 34.9211 - val_loss: 170.0535 - val_root_mean_squared_error: 13.0405\n",
      "Epoch 75/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1121.3326 - root_mean_squared_error: 33.4863 - val_loss: 128.9112 - val_root_mean_squared_error: 11.3539\n",
      "Epoch 76/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 1046.2509 - root_mean_squared_error: 32.3458 - val_loss: 129.0502 - val_root_mean_squared_error: 11.3600\n",
      "Epoch 77/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 957.1234 - root_mean_squared_error: 30.9374 - val_loss: 112.9781 - val_root_mean_squared_error: 10.6291\n",
      "Epoch 78/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 879.7872 - root_mean_squared_error: 29.6612 - val_loss: 169.6945 - val_root_mean_squared_error: 13.0267\n",
      "Epoch 79/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 842.3547 - root_mean_squared_error: 29.0233 - val_loss: 143.0339 - val_root_mean_squared_error: 11.9597\n",
      "Epoch 80/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 750.7850 - root_mean_squared_error: 27.4005 - val_loss: 155.5376 - val_root_mean_squared_error: 12.4715\n",
      "Epoch 81/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 704.9158 - root_mean_squared_error: 26.5503 - val_loss: 371.7332 - val_root_mean_squared_error: 19.2804\n",
      "Epoch 82/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 637.2809 - root_mean_squared_error: 25.2444 - val_loss: 129.0858 - val_root_mean_squared_error: 11.3616\n",
      "Epoch 83/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 567.0496 - root_mean_squared_error: 23.8128 - val_loss: 116.8976 - val_root_mean_squared_error: 10.8119\n",
      "Epoch 84/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 530.6227 - root_mean_squared_error: 23.0352 - val_loss: 163.0838 - val_root_mean_squared_error: 12.7704\n",
      "Epoch 85/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 472.7666 - root_mean_squared_error: 21.7432 - val_loss: 110.2815 - val_root_mean_squared_error: 10.5015\n",
      "Epoch 86/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 426.4674 - root_mean_squared_error: 20.6511 - val_loss: 108.8812 - val_root_mean_squared_error: 10.4346\n",
      "Epoch 87/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 390.8387 - root_mean_squared_error: 19.7696 - val_loss: 102.0710 - val_root_mean_squared_error: 10.1030\n",
      "Epoch 88/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 342.5398 - root_mean_squared_error: 18.5078 - val_loss: 124.0730 - val_root_mean_squared_error: 11.1388\n",
      "Epoch 89/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 309.7608 - root_mean_squared_error: 17.6000 - val_loss: 102.0935 - val_root_mean_squared_error: 10.1041\n",
      "Epoch 90/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 281.2473 - root_mean_squared_error: 16.7704 - val_loss: 107.2981 - val_root_mean_squared_error: 10.3585\n",
      "Epoch 91/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 252.5935 - root_mean_squared_error: 15.8932 - val_loss: 187.1766 - val_root_mean_squared_error: 13.6812\n",
      "Epoch 92/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 228.9495 - root_mean_squared_error: 15.1311 - val_loss: 110.7459 - val_root_mean_squared_error: 10.5236\n",
      "Epoch 93/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 205.8482 - root_mean_squared_error: 14.3474 - val_loss: 101.6447 - val_root_mean_squared_error: 10.0819\n",
      "Epoch 94/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 190.4712 - root_mean_squared_error: 13.8011 - val_loss: 97.8791 - val_root_mean_squared_error: 9.8934\n",
      "Epoch 95/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 172.6317 - root_mean_squared_error: 13.1389 - val_loss: 95.0138 - val_root_mean_squared_error: 9.7475\n",
      "Epoch 96/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 161.7378 - root_mean_squared_error: 12.7176 - val_loss: 96.9069 - val_root_mean_squared_error: 9.8441\n",
      "Epoch 97/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 145.7051 - root_mean_squared_error: 12.0708 - val_loss: 100.2980 - val_root_mean_squared_error: 10.0149\n",
      "Epoch 98/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 140.0540 - root_mean_squared_error: 11.8344 - val_loss: 133.1821 - val_root_mean_squared_error: 11.5405\n",
      "Epoch 99/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 134.5994 - root_mean_squared_error: 11.6017 - val_loss: 123.0822 - val_root_mean_squared_error: 11.0942\n",
      "Epoch 100/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 123.9990 - root_mean_squared_error: 11.1355 - val_loss: 139.7368 - val_root_mean_squared_error: 11.8210\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 136.4507 - root_mean_squared_error: 11.6812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 136.45065307617188, 'root_mean_squared_error': 11.681209564208984}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Red Neuronal 3\n",
    "\n",
    "\n",
    "''' \n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "Es te resultado unicamente escalando\n",
    "{'loss': 113.59896850585938, 'root_mean_squared_error': 10.658281326293945}\n",
    "'''\n",
    "# Build the model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, Y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=30 must be between 0 and min(n_samples, n_features)=12 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Aplicar PCA para reducir la dimensionalidad\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)  \u001b[38;5;66;03m# Elegir el nÃºmero de componentes principales deseado\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X_train_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m      4\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Definir la arquitectura de la red neuronal\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \n\u001b[0;32m    441\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;124;03mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 462\u001b[0m U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[0;32m    463\u001b[0m U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_full(X, n_components)\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[1;32mc:\\Users\\Usuario\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_pca.py:526\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    523\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    524\u001b[0m         )\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    529\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[0;32m    530\u001b[0m     )\n\u001b[0;32m    532\u001b[0m \u001b[38;5;66;03m# Center data\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=30 must be between 0 and min(n_samples, n_features)=12 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "# Aplicar PCA para reducir la dimensionalidad\n",
    "pca = PCA(n_components=30)  # Elegir el nÃºmero de componentes principales deseado\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_pca.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pca, Y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test_pca, Y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 75093.5625 - root_mean_squared_error: 274.0320 - val_loss: 1068.4614 - val_root_mean_squared_error: 32.6873\n",
      "Epoch 2/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 719.0242 - root_mean_squared_error: 26.8146 - val_loss: 410.9521 - val_root_mean_squared_error: 20.2720\n",
      "Epoch 3/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 424.0192 - root_mean_squared_error: 20.5917 - val_loss: 274.3079 - val_root_mean_squared_error: 16.5622\n",
      "Epoch 4/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 341.8751 - root_mean_squared_error: 18.4899 - val_loss: 215.2811 - val_root_mean_squared_error: 14.6725\n",
      "Epoch 5/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 329.7806 - root_mean_squared_error: 18.1599 - val_loss: 494.1411 - val_root_mean_squared_error: 22.2293\n",
      "Epoch 6/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 381.3821 - root_mean_squared_error: 19.5290 - val_loss: 185.8385 - val_root_mean_squared_error: 13.6323\n",
      "Epoch 7/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 379.9169 - root_mean_squared_error: 19.4915 - val_loss: 329.7704 - val_root_mean_squared_error: 18.1596\n",
      "Epoch 8/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 340.7220 - root_mean_squared_error: 18.4587 - val_loss: 111.6939 - val_root_mean_squared_error: 10.5685\n",
      "Epoch 9/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 371.0121 - root_mean_squared_error: 19.2617 - val_loss: 136.3457 - val_root_mean_squared_error: 11.6767\n",
      "Epoch 10/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 339.5229 - root_mean_squared_error: 18.4261 - val_loss: 828.7835 - val_root_mean_squared_error: 28.7886\n",
      "Epoch 11/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 358.2113 - root_mean_squared_error: 18.9265 - val_loss: 112.6497 - val_root_mean_squared_error: 10.6137\n",
      "Epoch 12/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 286.5394 - root_mean_squared_error: 16.9275 - val_loss: 183.9359 - val_root_mean_squared_error: 13.5623\n",
      "Epoch 13/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 307.7893 - root_mean_squared_error: 17.5439 - val_loss: 273.8061 - val_root_mean_squared_error: 16.5471\n",
      "Epoch 14/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 302.3759 - root_mean_squared_error: 17.3890 - val_loss: 180.9966 - val_root_mean_squared_error: 13.4535\n",
      "Epoch 15/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 295.8545 - root_mean_squared_error: 17.2004 - val_loss: 176.6586 - val_root_mean_squared_error: 13.2913\n",
      "Epoch 16/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 272.0423 - root_mean_squared_error: 16.4937 - val_loss: 180.4294 - val_root_mean_squared_error: 13.4324\n",
      "Epoch 17/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 289.9626 - root_mean_squared_error: 17.0283 - val_loss: 772.8957 - val_root_mean_squared_error: 27.8010\n",
      "Epoch 18/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 252.0221 - root_mean_squared_error: 15.8752 - val_loss: 188.0263 - val_root_mean_squared_error: 13.7123\n",
      "Epoch 19/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 253.5361 - root_mean_squared_error: 15.9228 - val_loss: 104.9064 - val_root_mean_squared_error: 10.2424\n",
      "Epoch 20/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 232.1706 - root_mean_squared_error: 15.2371 - val_loss: 501.9847 - val_root_mean_squared_error: 22.4050\n",
      "Epoch 21/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 247.0323 - root_mean_squared_error: 15.7173 - val_loss: 737.2231 - val_root_mean_squared_error: 27.1519\n",
      "Epoch 22/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 248.9479 - root_mean_squared_error: 15.7781 - val_loss: 95.1047 - val_root_mean_squared_error: 9.7522\n",
      "Epoch 23/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 240.2550 - root_mean_squared_error: 15.5002 - val_loss: 597.9815 - val_root_mean_squared_error: 24.4537\n",
      "Epoch 24/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 217.7903 - root_mean_squared_error: 14.7577 - val_loss: 112.3435 - val_root_mean_squared_error: 10.5992\n",
      "Epoch 25/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 216.0856 - root_mean_squared_error: 14.6999 - val_loss: 118.4852 - val_root_mean_squared_error: 10.8851\n",
      "Epoch 26/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 201.0326 - root_mean_squared_error: 14.1786 - val_loss: 118.7543 - val_root_mean_squared_error: 10.8974\n",
      "Epoch 27/100\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 211.0085 - root_mean_squared_error: 14.5261 - val_loss: 130.7198 - val_root_mean_squared_error: 11.4333\n",
      "Epoch 28/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 188.6055 - root_mean_squared_error: 13.7334 - val_loss: 256.1374 - val_root_mean_squared_error: 16.0043\n",
      "Epoch 29/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 213.6064 - root_mean_squared_error: 14.6153 - val_loss: 181.8494 - val_root_mean_squared_error: 13.4852\n",
      "Epoch 30/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 175.0343 - root_mean_squared_error: 13.2301 - val_loss: 491.7795 - val_root_mean_squared_error: 22.1761\n",
      "Epoch 31/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 207.1436 - root_mean_squared_error: 14.3925 - val_loss: 96.9385 - val_root_mean_squared_error: 9.8457\n",
      "Epoch 32/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 180.5298 - root_mean_squared_error: 13.4361 - val_loss: 155.7623 - val_root_mean_squared_error: 12.4805\n",
      "Epoch 33/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 176.6371 - root_mean_squared_error: 13.2905 - val_loss: 117.3383 - val_root_mean_squared_error: 10.8323\n",
      "Epoch 34/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 210.3629 - root_mean_squared_error: 14.5039 - val_loss: 155.1268 - val_root_mean_squared_error: 12.4550\n",
      "Epoch 35/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 180.7775 - root_mean_squared_error: 13.4454 - val_loss: 207.6689 - val_root_mean_squared_error: 14.4107\n",
      "Epoch 36/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 168.4689 - root_mean_squared_error: 12.9796 - val_loss: 225.7005 - val_root_mean_squared_error: 15.0233\n",
      "Epoch 37/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 183.6394 - root_mean_squared_error: 13.5514 - val_loss: 96.8139 - val_root_mean_squared_error: 9.8394\n",
      "Epoch 38/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 154.8884 - root_mean_squared_error: 12.4454 - val_loss: 193.6852 - val_root_mean_squared_error: 13.9171\n",
      "Epoch 39/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 191.8360 - root_mean_squared_error: 13.8505 - val_loss: 124.1838 - val_root_mean_squared_error: 11.1438\n",
      "Epoch 40/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 172.4633 - root_mean_squared_error: 13.1325 - val_loss: 124.2955 - val_root_mean_squared_error: 11.1488\n",
      "Epoch 41/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 157.9764 - root_mean_squared_error: 12.5689 - val_loss: 169.8464 - val_root_mean_squared_error: 13.0325\n",
      "Epoch 42/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 167.2566 - root_mean_squared_error: 12.9328 - val_loss: 97.0837 - val_root_mean_squared_error: 9.8531\n",
      "Epoch 43/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 167.5718 - root_mean_squared_error: 12.9450 - val_loss: 393.1756 - val_root_mean_squared_error: 19.8287\n",
      "Epoch 44/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 159.4527 - root_mean_squared_error: 12.6275 - val_loss: 308.6552 - val_root_mean_squared_error: 17.5686\n",
      "Epoch 45/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 155.1765 - root_mean_squared_error: 12.4570 - val_loss: 98.3058 - val_root_mean_squared_error: 9.9149\n",
      "Epoch 46/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 163.9325 - root_mean_squared_error: 12.8036 - val_loss: 97.3397 - val_root_mean_squared_error: 9.8661\n",
      "Epoch 47/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 159.6150 - root_mean_squared_error: 12.6339 - val_loss: 111.1257 - val_root_mean_squared_error: 10.5416\n",
      "Epoch 48/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 155.9974 - root_mean_squared_error: 12.4899 - val_loss: 93.6740 - val_root_mean_squared_error: 9.6785\n",
      "Epoch 49/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 154.6081 - root_mean_squared_error: 12.4342 - val_loss: 117.8495 - val_root_mean_squared_error: 10.8559\n",
      "Epoch 50/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 152.1591 - root_mean_squared_error: 12.3353 - val_loss: 97.6595 - val_root_mean_squared_error: 9.8823\n",
      "Epoch 51/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 157.3544 - root_mean_squared_error: 12.5441 - val_loss: 160.9824 - val_root_mean_squared_error: 12.6879\n",
      "Epoch 52/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 156.0191 - root_mean_squared_error: 12.4908 - val_loss: 108.5391 - val_root_mean_squared_error: 10.4182\n",
      "Epoch 53/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 169.8051 - root_mean_squared_error: 13.0309 - val_loss: 215.2305 - val_root_mean_squared_error: 14.6707\n",
      "Epoch 54/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 143.4505 - root_mean_squared_error: 11.9771 - val_loss: 140.4397 - val_root_mean_squared_error: 11.8507\n",
      "Epoch 55/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 153.2524 - root_mean_squared_error: 12.3795 - val_loss: 161.9007 - val_root_mean_squared_error: 12.7240\n",
      "Epoch 56/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 141.7751 - root_mean_squared_error: 11.9069 - val_loss: 94.5457 - val_root_mean_squared_error: 9.7235\n",
      "Epoch 57/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 154.5879 - root_mean_squared_error: 12.4333 - val_loss: 101.9605 - val_root_mean_squared_error: 10.0976\n",
      "Epoch 58/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 153.2289 - root_mean_squared_error: 12.3786 - val_loss: 111.8457 - val_root_mean_squared_error: 10.5757\n",
      "Epoch 59/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 149.6193 - root_mean_squared_error: 12.2319 - val_loss: 93.5312 - val_root_mean_squared_error: 9.6712\n",
      "Epoch 60/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 158.5297 - root_mean_squared_error: 12.5909 - val_loss: 93.1808 - val_root_mean_squared_error: 9.6530\n",
      "Epoch 61/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 147.6229 - root_mean_squared_error: 12.1500 - val_loss: 295.8119 - val_root_mean_squared_error: 17.1992\n",
      "Epoch 62/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 150.2571 - root_mean_squared_error: 12.2579 - val_loss: 295.5183 - val_root_mean_squared_error: 17.1906\n",
      "Epoch 63/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 164.0181 - root_mean_squared_error: 12.8070 - val_loss: 116.3064 - val_root_mean_squared_error: 10.7845\n",
      "Epoch 64/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 138.7848 - root_mean_squared_error: 11.7807 - val_loss: 95.1794 - val_root_mean_squared_error: 9.7560\n",
      "Epoch 65/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 149.7750 - root_mean_squared_error: 12.2383 - val_loss: 185.6716 - val_root_mean_squared_error: 13.6261\n",
      "Epoch 66/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 145.2753 - root_mean_squared_error: 12.0530 - val_loss: 93.2937 - val_root_mean_squared_error: 9.6589\n",
      "Epoch 67/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 155.2501 - root_mean_squared_error: 12.4599 - val_loss: 206.5150 - val_root_mean_squared_error: 14.3706\n",
      "Epoch 68/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 154.3461 - root_mean_squared_error: 12.4236 - val_loss: 318.2334 - val_root_mean_squared_error: 17.8391\n",
      "Epoch 69/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 149.5670 - root_mean_squared_error: 12.2298 - val_loss: 277.1636 - val_root_mean_squared_error: 16.6482\n",
      "Epoch 70/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 148.4596 - root_mean_squared_error: 12.1844 - val_loss: 122.1637 - val_root_mean_squared_error: 11.0528\n",
      "Epoch 71/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 142.7484 - root_mean_squared_error: 11.9477 - val_loss: 93.8965 - val_root_mean_squared_error: 9.6900\n",
      "Epoch 72/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 138.1090 - root_mean_squared_error: 11.7520 - val_loss: 98.3784 - val_root_mean_squared_error: 9.9186\n",
      "Epoch 73/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 141.9340 - root_mean_squared_error: 11.9136 - val_loss: 98.7141 - val_root_mean_squared_error: 9.9355\n",
      "Epoch 74/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 150.0415 - root_mean_squared_error: 12.2491 - val_loss: 628.3307 - val_root_mean_squared_error: 25.0665\n",
      "Epoch 75/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 148.9432 - root_mean_squared_error: 12.2042 - val_loss: 105.1827 - val_root_mean_squared_error: 10.2559\n",
      "Epoch 76/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 140.3528 - root_mean_squared_error: 11.8471 - val_loss: 117.5736 - val_root_mean_squared_error: 10.8431\n",
      "Epoch 77/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 149.2023 - root_mean_squared_error: 12.2148 - val_loss: 95.2489 - val_root_mean_squared_error: 9.7596\n",
      "Epoch 78/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 137.2392 - root_mean_squared_error: 11.7149 - val_loss: 244.7403 - val_root_mean_squared_error: 15.6442\n",
      "Epoch 79/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 151.3939 - root_mean_squared_error: 12.3042 - val_loss: 285.0161 - val_root_mean_squared_error: 16.8824\n",
      "Epoch 80/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 142.8732 - root_mean_squared_error: 11.9530 - val_loss: 112.0155 - val_root_mean_squared_error: 10.5837\n",
      "Epoch 81/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 152.2174 - root_mean_squared_error: 12.3376 - val_loss: 385.8348 - val_root_mean_squared_error: 19.6427\n",
      "Epoch 82/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 151.2695 - root_mean_squared_error: 12.2992 - val_loss: 108.5146 - val_root_mean_squared_error: 10.4170\n",
      "Epoch 83/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 144.3618 - root_mean_squared_error: 12.0151 - val_loss: 152.5131 - val_root_mean_squared_error: 12.3496\n",
      "Epoch 84/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 143.2887 - root_mean_squared_error: 11.9703 - val_loss: 105.7247 - val_root_mean_squared_error: 10.2822\n",
      "Epoch 85/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 147.9050 - root_mean_squared_error: 12.1616 - val_loss: 95.6785 - val_root_mean_squared_error: 9.7815\n",
      "Epoch 86/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 138.0240 - root_mean_squared_error: 11.7484 - val_loss: 130.1532 - val_root_mean_squared_error: 11.4085\n",
      "Epoch 87/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 132.9086 - root_mean_squared_error: 11.5286 - val_loss: 234.9162 - val_root_mean_squared_error: 15.3270\n",
      "Epoch 88/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 130.6310 - root_mean_squared_error: 11.4294 - val_loss: 96.5998 - val_root_mean_squared_error: 9.8285\n",
      "Epoch 89/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 152.8132 - root_mean_squared_error: 12.3618 - val_loss: 104.9282 - val_root_mean_squared_error: 10.2434\n",
      "Epoch 90/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 144.5901 - root_mean_squared_error: 12.0246 - val_loss: 114.5805 - val_root_mean_squared_error: 10.7042\n",
      "Epoch 91/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 138.4570 - root_mean_squared_error: 11.7668 - val_loss: 99.5380 - val_root_mean_squared_error: 9.9769\n",
      "Epoch 92/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 141.5151 - root_mean_squared_error: 11.8960 - val_loss: 94.9057 - val_root_mean_squared_error: 9.7420\n",
      "Epoch 93/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 150.0807 - root_mean_squared_error: 12.2507 - val_loss: 114.5838 - val_root_mean_squared_error: 10.7044\n",
      "Epoch 94/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 150.8966 - root_mean_squared_error: 12.2840 - val_loss: 142.3891 - val_root_mean_squared_error: 11.9327\n",
      "Epoch 95/100\n",
      "778/778 [==============================] - 2s 3ms/step - loss: 142.4226 - root_mean_squared_error: 11.9341 - val_loss: 130.1764 - val_root_mean_squared_error: 11.4095\n",
      "Epoch 96/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 139.2741 - root_mean_squared_error: 11.8014 - val_loss: 97.1109 - val_root_mean_squared_error: 9.8545\n",
      "Epoch 97/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 144.8902 - root_mean_squared_error: 12.0370 - val_loss: 105.0246 - val_root_mean_squared_error: 10.2482\n",
      "Epoch 98/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 146.6957 - root_mean_squared_error: 12.1118 - val_loss: 186.7087 - val_root_mean_squared_error: 13.6641\n",
      "Epoch 99/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 136.6098 - root_mean_squared_error: 11.6880 - val_loss: 93.4433 - val_root_mean_squared_error: 9.6666\n",
      "Epoch 100/100\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 136.9466 - root_mean_squared_error: 11.7024 - val_loss: 149.2127 - val_root_mean_squared_error: 12.2153\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 148.7280 - root_mean_squared_error: 12.1954\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 148.72802734375, 'root_mean_squared_error': 12.195409774780273}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnas_predictoras= ['ID', 'Y','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10','V11', 'V12']\n",
    "\n",
    "data_2 = data [columnas_predictoras]\n",
    "\n",
    "\n",
    "# Dividir los datos en caracterÃ­sticas (X) y etiquetas (Y)\n",
    "X = data_2.drop(['ID', 'Y'], axis=1).values\n",
    "Y = data_2['Y'].values\n",
    "\n",
    "# Escalar las caracterÃ­sticas para mejorar el rendimiento del modelo\n",
    "#scaler = StandardScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1,activation='linear'))\n",
    "\n",
    "\n",
    "# Compile the models\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, Y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 298958.0312 - val_loss: 354.1000\n",
      "Epoch 2/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 314.5061 - val_loss: 267.6972\n",
      "Epoch 3/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 255.3907 - val_loss: 236.2348\n",
      "Epoch 4/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 229.1446 - val_loss: 203.7117\n",
      "Epoch 5/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 218.7951 - val_loss: 196.7157\n",
      "Epoch 6/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 211.7582 - val_loss: 226.6539\n",
      "Epoch 7/100\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 200.1850 - val_loss: 180.8801\n",
      "Epoch 8/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 192.9982 - val_loss: 177.1471\n",
      "Epoch 9/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 188.5015 - val_loss: 201.1738\n",
      "Epoch 10/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 188.1184 - val_loss: 187.6820\n",
      "Epoch 11/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 180.9184 - val_loss: 162.4533\n",
      "Epoch 12/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 178.0052 - val_loss: 161.8146\n",
      "Epoch 13/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 174.8796 - val_loss: 160.0711\n",
      "Epoch 14/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 174.2442 - val_loss: 171.9794\n",
      "Epoch 15/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 172.9440 - val_loss: 166.0760\n",
      "Epoch 16/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 170.0830 - val_loss: 151.0050\n",
      "Epoch 17/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 169.8251 - val_loss: 177.1035\n",
      "Epoch 18/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 169.2806 - val_loss: 160.3281\n",
      "Epoch 19/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 165.3900 - val_loss: 199.9724\n",
      "Epoch 20/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 166.2794 - val_loss: 146.6106\n",
      "Epoch 21/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 166.7415 - val_loss: 164.9882\n",
      "Epoch 22/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 164.2279 - val_loss: 144.7268\n",
      "Epoch 23/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 163.6182 - val_loss: 160.1325\n",
      "Epoch 24/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 163.3827 - val_loss: 143.4933\n",
      "Epoch 25/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 163.9612 - val_loss: 197.0219\n",
      "Epoch 26/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 159.3601 - val_loss: 141.9785\n",
      "Epoch 27/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 164.5424 - val_loss: 155.1709\n",
      "Epoch 28/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 162.4716 - val_loss: 148.7872\n",
      "Epoch 29/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 159.0644 - val_loss: 160.9198\n",
      "Epoch 30/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 159.2071 - val_loss: 139.8811\n",
      "Epoch 31/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 159.5564 - val_loss: 139.0637\n",
      "Epoch 32/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 158.2837 - val_loss: 139.5850\n",
      "Epoch 33/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 160.6919 - val_loss: 144.9604\n",
      "Epoch 34/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 155.4904 - val_loss: 141.1907\n",
      "Epoch 35/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 157.7904 - val_loss: 169.7135\n",
      "Epoch 36/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 156.4153 - val_loss: 138.9749\n",
      "Epoch 37/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 156.9951 - val_loss: 140.2631\n",
      "Epoch 38/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 156.1154 - val_loss: 142.8132\n",
      "Epoch 39/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 154.7760 - val_loss: 149.2991\n",
      "Epoch 40/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 154.4997 - val_loss: 137.8814\n",
      "Epoch 41/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 155.8314 - val_loss: 138.9264\n",
      "Epoch 42/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 154.3765 - val_loss: 138.1397\n",
      "Epoch 43/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 154.9442 - val_loss: 136.1084\n",
      "Epoch 44/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 155.2283 - val_loss: 185.3306\n",
      "Epoch 45/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 152.8271 - val_loss: 135.9902\n",
      "Epoch 46/100\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 154.4230 - val_loss: 134.3531\n",
      "Epoch 47/100\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 152.3013 - val_loss: 232.8076\n",
      "Epoch 48/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 153.2080 - val_loss: 178.0684\n",
      "Epoch 49/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 151.2419 - val_loss: 161.7910\n",
      "Epoch 50/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 151.2341 - val_loss: 132.9277\n",
      "Epoch 51/100\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 150.8500 - val_loss: 138.5981\n",
      "Epoch 52/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 151.8810 - val_loss: 140.5389\n",
      "Epoch 53/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 149.9834 - val_loss: 146.8728\n",
      "Epoch 54/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 151.1492 - val_loss: 133.1671\n",
      "Epoch 55/100\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 150.1395 - val_loss: 134.3753\n",
      "487/487 [==============================] - 1s 1ms/step\n",
      "RMSE en el conjunto de prueba con caracterÃ­sticas seleccionadas por red neuronal: 11.83328080068904\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1\n",
    "\n",
    "# Dividir los datos en caracterÃ­sticas (X) y etiquetas (Y)\n",
    "X = data.drop(['ID', 'Y'], axis=1)\n",
    "Y = data['Y']\n",
    "\n",
    "# Estandarizar las caracterÃ­sticas\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Definir el modelo de red neuronal con regularizaciÃ³n L1 (Lasso)\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l1(0.001)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l1(0.001)),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Entrenar el modelo con early stopping para evitar sobreajuste\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model.fit(X_train, Y_train, validation_split=0.1, epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = model.predict(X_test).flatten()\n",
    "\n",
    "# Calcular el RMSE en el conjunto de datos de prueba\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, predictions))\n",
    "print(\"RMSE en el conjunto de prueba con caracterÃ­sticas seleccionadas por red neuronal:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
       "       'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40',\n",
       "       'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50',\n",
       "       'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60',\n",
       "       'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70',\n",
       "       'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80',\n",
       "       'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargue datos Test\n",
    "test_data = pd.read_csv('testReg.csv')\n",
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Para Cargue Kaggle \n",
    "\n",
    "# Preprocesar los datos de prueba (escalar las caracterÃ­sticas)\n",
    "X_test_scaled = scaler.transform(test_data.drop('ID', axis=1).values)\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Redondear las predicciones a nÃºmeros enteros\n",
    "rounded_predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Crear un DataFrame con las columnas 'ID' y 'Y' utilizando las predicciones redondeadas\n",
    "submission_df = pd.DataFrame({'ID': test_data['ID'], 'Y': rounded_predictions})\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584/584 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "columnas_predictoras_cargue= ['ID','V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10','V11', 'V12']\n",
    "\n",
    "data_2_cargue = test_data[columnas_predictoras_cargue]\n",
    "\n",
    "# Para Cargue Kaggle \n",
    "\n",
    "# Preprocesar los datos de prueba (escalar las caracterÃ­sticas)\n",
    "X_test_scaled = scaler.transform(data_2_cargue.drop('ID', axis=1).values)\n",
    "\n",
    "# Realizar predicciones en el conjunto de datos de prueba\n",
    "predictions = model.predict(X_test_scaled).flatten()\n",
    "\n",
    "# Redondear las predicciones a nÃºmeros enteros\n",
    "#rounded_predictions = np.round(predictions).astype(int)\n",
    "\n",
    "# Crear un DataFrame con las columnas 'ID' y 'Y' utilizando las predicciones redondeadas\n",
    "submission_df = pd.DataFrame({'ID': test_data['ID'], 'Y': predictions})\n",
    "\n",
    "# Guardar el DataFrame en un archivo CSV\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 527910.8750 - root_mean_squared_error: 726.5748 - val_loss: 1466.0948 - val_root_mean_squared_error: 38.2896\n",
      "Epoch 2/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 949.1845 - root_mean_squared_error: 30.8088 - val_loss: 639.2573 - val_root_mean_squared_error: 25.2835\n",
      "Epoch 3/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 567.7411 - root_mean_squared_error: 23.8273 - val_loss: 497.2438 - val_root_mean_squared_error: 22.2990\n",
      "Epoch 4/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 488.8208 - root_mean_squared_error: 22.1093 - val_loss: 448.8206 - val_root_mean_squared_error: 21.1854\n",
      "Epoch 5/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 449.7389 - root_mean_squared_error: 21.2070 - val_loss: 417.7453 - val_root_mean_squared_error: 20.4388\n",
      "Epoch 6/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 420.9922 - root_mean_squared_error: 20.5181 - val_loss: 388.6014 - val_root_mean_squared_error: 19.7130\n",
      "Epoch 7/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 396.0599 - root_mean_squared_error: 19.9013 - val_loss: 373.0374 - val_root_mean_squared_error: 19.3142\n",
      "Epoch 8/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 375.6862 - root_mean_squared_error: 19.3826 - val_loss: 382.6649 - val_root_mean_squared_error: 19.5618\n",
      "Epoch 9/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 360.0445 - root_mean_squared_error: 18.9748 - val_loss: 322.0554 - val_root_mean_squared_error: 17.9459\n",
      "Epoch 10/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 335.7465 - root_mean_squared_error: 18.3234 - val_loss: 335.7071 - val_root_mean_squared_error: 18.3223\n",
      "Epoch 11/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 323.1870 - root_mean_squared_error: 17.9774 - val_loss: 354.4403 - val_root_mean_squared_error: 18.8266\n",
      "Epoch 12/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 304.8824 - root_mean_squared_error: 17.4609 - val_loss: 285.1964 - val_root_mean_squared_error: 16.8878\n",
      "Epoch 13/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 298.2632 - root_mean_squared_error: 17.2703 - val_loss: 311.7197 - val_root_mean_squared_error: 17.6556\n",
      "Epoch 14/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 283.2653 - root_mean_squared_error: 16.8305 - val_loss: 261.4159 - val_root_mean_squared_error: 16.1684\n",
      "Epoch 15/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 275.5664 - root_mean_squared_error: 16.6002 - val_loss: 253.3631 - val_root_mean_squared_error: 15.9174\n",
      "Epoch 16/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 264.8981 - root_mean_squared_error: 16.2757 - val_loss: 239.7231 - val_root_mean_squared_error: 15.4830\n",
      "Epoch 17/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 257.6960 - root_mean_squared_error: 16.0529 - val_loss: 234.0188 - val_root_mean_squared_error: 15.2977\n",
      "Epoch 18/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 251.9811 - root_mean_squared_error: 15.8739 - val_loss: 224.2611 - val_root_mean_squared_error: 14.9754\n",
      "Epoch 19/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 245.2555 - root_mean_squared_error: 15.6606 - val_loss: 276.2055 - val_root_mean_squared_error: 16.6194\n",
      "Epoch 20/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 236.2468 - root_mean_squared_error: 15.3703 - val_loss: 229.1599 - val_root_mean_squared_error: 15.1380\n",
      "Epoch 21/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 224.1686 - root_mean_squared_error: 14.9723 - val_loss: 231.1050 - val_root_mean_squared_error: 15.2021\n",
      "Epoch 22/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 224.2083 - root_mean_squared_error: 14.9736 - val_loss: 217.7825 - val_root_mean_squared_error: 14.7575\n",
      "Epoch 23/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 213.1717 - root_mean_squared_error: 14.6004 - val_loss: 197.4830 - val_root_mean_squared_error: 14.0529\n",
      "Epoch 24/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 209.3206 - root_mean_squared_error: 14.4679 - val_loss: 195.1392 - val_root_mean_squared_error: 13.9692\n",
      "Epoch 25/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 203.7993 - root_mean_squared_error: 14.2758 - val_loss: 226.5672 - val_root_mean_squared_error: 15.0522\n",
      "Epoch 26/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 193.9248 - root_mean_squared_error: 13.9257 - val_loss: 199.6776 - val_root_mean_squared_error: 14.1307\n",
      "Epoch 27/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 187.0971 - root_mean_squared_error: 13.6783 - val_loss: 171.5487 - val_root_mean_squared_error: 13.0977\n",
      "Epoch 28/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 188.4416 - root_mean_squared_error: 13.7274 - val_loss: 190.5745 - val_root_mean_squared_error: 13.8049\n",
      "Epoch 29/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 177.8107 - root_mean_squared_error: 13.3346 - val_loss: 161.2671 - val_root_mean_squared_error: 12.6991\n",
      "Epoch 30/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 174.6254 - root_mean_squared_error: 13.2146 - val_loss: 154.2943 - val_root_mean_squared_error: 12.4215\n",
      "Epoch 31/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 174.7742 - root_mean_squared_error: 13.2202 - val_loss: 161.3592 - val_root_mean_squared_error: 12.7027\n",
      "Epoch 32/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 167.8586 - root_mean_squared_error: 12.9560 - val_loss: 146.0361 - val_root_mean_squared_error: 12.0845\n",
      "Epoch 33/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 157.1123 - root_mean_squared_error: 12.5344 - val_loss: 168.2752 - val_root_mean_squared_error: 12.9721\n",
      "Epoch 34/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 155.3511 - root_mean_squared_error: 12.4640 - val_loss: 136.9805 - val_root_mean_squared_error: 11.7039\n",
      "Epoch 35/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 149.3818 - root_mean_squared_error: 12.2222 - val_loss: 135.5930 - val_root_mean_squared_error: 11.6444\n",
      "Epoch 36/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 149.2785 - root_mean_squared_error: 12.2180 - val_loss: 136.4662 - val_root_mean_squared_error: 11.6819\n",
      "Epoch 37/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 145.1543 - root_mean_squared_error: 12.0480 - val_loss: 130.9875 - val_root_mean_squared_error: 11.4450\n",
      "Epoch 38/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 137.9050 - root_mean_squared_error: 11.7433 - val_loss: 159.5532 - val_root_mean_squared_error: 12.6314\n",
      "Epoch 39/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 137.9762 - root_mean_squared_error: 11.7463 - val_loss: 139.4635 - val_root_mean_squared_error: 11.8095\n",
      "Epoch 40/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 135.6096 - root_mean_squared_error: 11.6452 - val_loss: 134.1426 - val_root_mean_squared_error: 11.5820\n",
      "Epoch 41/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 130.1757 - root_mean_squared_error: 11.4095 - val_loss: 114.1449 - val_root_mean_squared_error: 10.6839\n",
      "Epoch 42/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 125.1469 - root_mean_squared_error: 11.1869 - val_loss: 115.5777 - val_root_mean_squared_error: 10.7507\n",
      "Epoch 43/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 127.8739 - root_mean_squared_error: 11.3081 - val_loss: 132.6381 - val_root_mean_squared_error: 11.5169\n",
      "Epoch 44/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 122.0200 - root_mean_squared_error: 11.0463 - val_loss: 125.2970 - val_root_mean_squared_error: 11.1936\n",
      "Epoch 45/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 121.1244 - root_mean_squared_error: 11.0057 - val_loss: 140.9533 - val_root_mean_squared_error: 11.8724\n",
      "Epoch 46/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 123.1822 - root_mean_squared_error: 11.0987 - val_loss: 103.3715 - val_root_mean_squared_error: 10.1672\n",
      "Epoch 47/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 115.1699 - root_mean_squared_error: 10.7317 - val_loss: 105.8836 - val_root_mean_squared_error: 10.2900\n",
      "Epoch 48/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 115.9706 - root_mean_squared_error: 10.7690 - val_loss: 155.1472 - val_root_mean_squared_error: 12.4558\n",
      "Epoch 49/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 115.0137 - root_mean_squared_error: 10.7244 - val_loss: 110.3293 - val_root_mean_squared_error: 10.5038\n",
      "Epoch 50/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 111.2995 - root_mean_squared_error: 10.5499 - val_loss: 102.5365 - val_root_mean_squared_error: 10.1260\n",
      "Epoch 51/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 113.0664 - root_mean_squared_error: 10.6333 - val_loss: 105.5742 - val_root_mean_squared_error: 10.2749\n",
      "Epoch 52/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 108.6588 - root_mean_squared_error: 10.4240 - val_loss: 95.6480 - val_root_mean_squared_error: 9.7800\n",
      "Epoch 53/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 108.8636 - root_mean_squared_error: 10.4338 - val_loss: 96.8695 - val_root_mean_squared_error: 9.8422\n",
      "Epoch 54/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 111.0238 - root_mean_squared_error: 10.5368 - val_loss: 98.8815 - val_root_mean_squared_error: 9.9439\n",
      "Epoch 55/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 109.0809 - root_mean_squared_error: 10.4442 - val_loss: 94.2790 - val_root_mean_squared_error: 9.7097\n",
      "Epoch 56/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 108.3610 - root_mean_squared_error: 10.4097 - val_loss: 108.2034 - val_root_mean_squared_error: 10.4021\n",
      "Epoch 57/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 103.7596 - root_mean_squared_error: 10.1862 - val_loss: 133.3916 - val_root_mean_squared_error: 11.5495\n",
      "Epoch 58/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 107.7621 - root_mean_squared_error: 10.3809 - val_loss: 136.0142 - val_root_mean_squared_error: 11.6625\n",
      "Epoch 59/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 108.5077 - root_mean_squared_error: 10.4167 - val_loss: 104.9016 - val_root_mean_squared_error: 10.2422\n",
      "Epoch 60/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 104.1504 - root_mean_squared_error: 10.2054 - val_loss: 97.3505 - val_root_mean_squared_error: 9.8666\n",
      "Epoch 61/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 108.1080 - root_mean_squared_error: 10.3975 - val_loss: 92.1775 - val_root_mean_squared_error: 9.6009\n",
      "Epoch 62/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 102.9308 - root_mean_squared_error: 10.1455 - val_loss: 91.2796 - val_root_mean_squared_error: 9.5540\n",
      "Epoch 63/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 105.1915 - root_mean_squared_error: 10.2563 - val_loss: 137.9252 - val_root_mean_squared_error: 11.7442\n",
      "Epoch 64/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 105.2450 - root_mean_squared_error: 10.2589 - val_loss: 94.0073 - val_root_mean_squared_error: 9.6957\n",
      "Epoch 65/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 105.0128 - root_mean_squared_error: 10.2476 - val_loss: 111.7205 - val_root_mean_squared_error: 10.5698\n",
      "Epoch 66/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 102.4016 - root_mean_squared_error: 10.1194 - val_loss: 96.4310 - val_root_mean_squared_error: 9.8199\n",
      "Epoch 67/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 100.9669 - root_mean_squared_error: 10.0482 - val_loss: 102.9711 - val_root_mean_squared_error: 10.1475\n",
      "Epoch 68/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 102.6804 - root_mean_squared_error: 10.1331 - val_loss: 90.1160 - val_root_mean_squared_error: 9.4929\n",
      "Epoch 69/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 105.4634 - root_mean_squared_error: 10.2695 - val_loss: 92.2755 - val_root_mean_squared_error: 9.6060\n",
      "Epoch 70/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 100.6138 - root_mean_squared_error: 10.0306 - val_loss: 107.0366 - val_root_mean_squared_error: 10.3458\n",
      "Epoch 71/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 103.9084 - root_mean_squared_error: 10.1935 - val_loss: 106.4325 - val_root_mean_squared_error: 10.3166\n",
      "Epoch 72/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 101.9299 - root_mean_squared_error: 10.0960 - val_loss: 112.3445 - val_root_mean_squared_error: 10.5993\n",
      "Epoch 73/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 102.9485 - root_mean_squared_error: 10.1464 - val_loss: 134.7016 - val_root_mean_squared_error: 11.6061\n",
      "Epoch 74/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 101.5459 - root_mean_squared_error: 10.0770 - val_loss: 101.0014 - val_root_mean_squared_error: 10.0499\n",
      "Epoch 75/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 105.7841 - root_mean_squared_error: 10.2851 - val_loss: 118.0230 - val_root_mean_squared_error: 10.8638\n",
      "Epoch 76/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 107.3272 - root_mean_squared_error: 10.3599 - val_loss: 138.0242 - val_root_mean_squared_error: 11.7484\n",
      "Epoch 77/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 99.7623 - root_mean_squared_error: 9.9881 - val_loss: 97.2717 - val_root_mean_squared_error: 9.8626\n",
      "Epoch 78/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 100.4088 - root_mean_squared_error: 10.0204 - val_loss: 89.9538 - val_root_mean_squared_error: 9.4844\n",
      "Epoch 79/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 97.6623 - root_mean_squared_error: 9.8824 - val_loss: 102.9526 - val_root_mean_squared_error: 10.1466\n",
      "Epoch 80/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 100.6894 - root_mean_squared_error: 10.0344 - val_loss: 87.9748 - val_root_mean_squared_error: 9.3795\n",
      "Epoch 81/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 101.5925 - root_mean_squared_error: 10.0793 - val_loss: 106.4756 - val_root_mean_squared_error: 10.3187\n",
      "Epoch 82/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 101.0118 - root_mean_squared_error: 10.0505 - val_loss: 90.4299 - val_root_mean_squared_error: 9.5095\n",
      "Epoch 83/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 100.6440 - root_mean_squared_error: 10.0321 - val_loss: 90.3589 - val_root_mean_squared_error: 9.5057\n",
      "Epoch 84/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 101.5283 - root_mean_squared_error: 10.0761 - val_loss: 86.8132 - val_root_mean_squared_error: 9.3174\n",
      "Epoch 85/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 104.3018 - root_mean_squared_error: 10.2128 - val_loss: 90.9869 - val_root_mean_squared_error: 9.5387\n",
      "Epoch 86/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 100.9723 - root_mean_squared_error: 10.0485 - val_loss: 88.7301 - val_root_mean_squared_error: 9.4197\n",
      "Epoch 87/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 102.1564 - root_mean_squared_error: 10.1072 - val_loss: 164.4850 - val_root_mean_squared_error: 12.8252\n",
      "Epoch 88/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 100.8230 - root_mean_squared_error: 10.0411 - val_loss: 89.0298 - val_root_mean_squared_error: 9.4356\n",
      "Epoch 89/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 101.1423 - root_mean_squared_error: 10.0570 - val_loss: 152.1252 - val_root_mean_squared_error: 12.3339\n",
      "Epoch 90/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 99.5045 - root_mean_squared_error: 9.9752 - val_loss: 94.5728 - val_root_mean_squared_error: 9.7249\n",
      "Epoch 91/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 101.5832 - root_mean_squared_error: 10.0788 - val_loss: 94.8987 - val_root_mean_squared_error: 9.7416\n",
      "Epoch 92/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 102.1829 - root_mean_squared_error: 10.1086 - val_loss: 86.1948 - val_root_mean_squared_error: 9.2841\n",
      "Epoch 93/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 101.7739 - root_mean_squared_error: 10.0883 - val_loss: 117.8158 - val_root_mean_squared_error: 10.8543\n",
      "Epoch 94/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 100.3658 - root_mean_squared_error: 10.0183 - val_loss: 87.9619 - val_root_mean_squared_error: 9.3788\n",
      "Epoch 95/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 102.1352 - root_mean_squared_error: 10.1062 - val_loss: 108.2507 - val_root_mean_squared_error: 10.4044\n",
      "Epoch 96/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 101.4253 - root_mean_squared_error: 10.0710 - val_loss: 94.5437 - val_root_mean_squared_error: 9.7234\n",
      "Epoch 97/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 101.9769 - root_mean_squared_error: 10.0984 - val_loss: 183.8717 - val_root_mean_squared_error: 13.5599\n",
      "Epoch 98/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 99.9602 - root_mean_squared_error: 9.9980 - val_loss: 86.3514 - val_root_mean_squared_error: 9.2925\n",
      "Epoch 99/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 100.3854 - root_mean_squared_error: 10.0193 - val_loss: 128.6194 - val_root_mean_squared_error: 11.3411\n",
      "Epoch 100/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 101.3543 - root_mean_squared_error: 10.0675 - val_loss: 108.0624 - val_root_mean_squared_error: 10.3953\n",
      "Epoch 101/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 100.6153 - root_mean_squared_error: 10.0307 - val_loss: 97.0261 - val_root_mean_squared_error: 9.8502\n",
      "Epoch 102/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 100.9176 - root_mean_squared_error: 10.0458 - val_loss: 96.5971 - val_root_mean_squared_error: 9.8284\n",
      "Epoch 103/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 101.2648 - root_mean_squared_error: 10.0630 - val_loss: 102.6995 - val_root_mean_squared_error: 10.1341\n",
      "Epoch 104/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 99.8577 - root_mean_squared_error: 9.9929 - val_loss: 93.0621 - val_root_mean_squared_error: 9.6469\n",
      "Epoch 105/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 99.0382 - root_mean_squared_error: 9.9518 - val_loss: 86.4072 - val_root_mean_squared_error: 9.2955\n",
      "Epoch 106/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 101.3561 - root_mean_squared_error: 10.0676 - val_loss: 100.1702 - val_root_mean_squared_error: 10.0085\n",
      "Epoch 107/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 103.2345 - root_mean_squared_error: 10.1604 - val_loss: 89.9554 - val_root_mean_squared_error: 9.4845\n",
      "Epoch 108/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 97.7285 - root_mean_squared_error: 9.8858 - val_loss: 97.5740 - val_root_mean_squared_error: 9.8780\n",
      "Epoch 109/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 103.0882 - root_mean_squared_error: 10.1532 - val_loss: 87.4181 - val_root_mean_squared_error: 9.3498\n",
      "Epoch 110/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 97.8378 - root_mean_squared_error: 9.8913 - val_loss: 95.8666 - val_root_mean_squared_error: 9.7911\n",
      "Epoch 111/1000\n",
      "778/778 [==============================] - 2s 2ms/step - loss: 102.9887 - root_mean_squared_error: 10.1483 - val_loss: 87.8664 - val_root_mean_squared_error: 9.3737\n",
      "Epoch 112/1000\n",
      "778/778 [==============================] - 1s 2ms/step - loss: 96.0257 - root_mean_squared_error: 9.7993 - val_loss: 88.7960 - val_root_mean_squared_error: 9.4232\n",
      "487/487 [==============================] - 1s 1ms/step - loss: 86.6054 - root_mean_squared_error: 9.3062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 86.60543823242188, 'root_mean_squared_error': 9.306203842163086}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n",
    "# Seleccionar las columnas predictoras\n",
    "columnas_predictoras = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
    "                        'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
    "                        'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'V29', 'V30',\n",
    "                        'V31', 'V32', 'V33', 'V34', 'V35', 'V36', 'V37', 'V38', 'V39', 'V40',\n",
    "                        'V41', 'V42', 'V43', 'V44', 'V45', 'V46', 'V47', 'V48', 'V49', 'V50',\n",
    "                        'V51', 'V52', 'V53', 'V54', 'V55', 'V56', 'V57', 'V58', 'V59', 'V60',\n",
    "                        'V61', 'V62', 'V63', 'V64', 'V65', 'V66', 'V67', 'V68', 'V69', 'V70',\n",
    "                        'V71', 'V72', 'V73', 'V74', 'V75', 'V76', 'V77', 'V78', 'V79', 'V80',\n",
    "                        'V81', 'V82', 'V83', 'V84', 'V85', 'V86', 'V87', 'V88', 'V89', 'V90']\n",
    "\n",
    "# Obtener los datos de las columnas predictoras\n",
    "X = data[columnas_predictoras].values\n",
    "Y = data['Y'].values\n",
    "\n",
    "# Escalar las caracterÃ­sticas para mejorar el rendimiento del modelo\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar el modelo de XGBoost para evaluar la importancia de las caracterÃ­sticas\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "# Seleccionar las caracterÃ­sticas mÃ¡s importantes utilizando XGBoost\n",
    "selector = SelectFromModel(xgb_model, prefit=True)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Definir la arquitectura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train_selected.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Definir Early Stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.001), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "\n",
    "# Entrenar el modelo con Early Stopping\n",
    "history = model.fit(X_train_selected, Y_train, epochs=1000, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "\n",
    "# Evaluar el modelo\n",
    "model.evaluate(X_test_selected, Y_test, return_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_xgb.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 574888.6875 - rmse: 617.5425 - val_loss: 102232.4219 - val_rmse: 311.4170\n",
      "Epoch 2/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 56044.2734 - rmse: 224.1680 - val_loss: 24226.7539 - val_rmse: 149.0222\n",
      "Epoch 3/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 12456.0879 - rmse: 102.7071 - val_loss: 5457.2217 - val_rmse: 67.0083\n",
      "Epoch 4/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 2371.8823 - rmse: 43.6663 - val_loss: 1687.0258 - val_rmse: 34.5697\n",
      "Epoch 5/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 714.8187 - rmse: 24.6455 - val_loss: 738.6257 - val_rmse: 23.7349\n",
      "Epoch 6/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 439.2543 - rmse: 19.5539 - val_loss: 425.3615 - val_rmse: 17.8589\n",
      "Epoch 7/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 433.9984 - rmse: 18.3314 - val_loss: 487.3541 - val_rmse: 19.0482\n",
      "Epoch 8/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 351.8130 - rmse: 16.7325 - val_loss: 254.4726 - val_rmse: 13.8929\n",
      "Epoch 9/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 274.9619 - rmse: 15.0991 - val_loss: 384.8747 - val_rmse: 17.3700\n",
      "Epoch 10/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 298.7410 - rmse: 15.7469 - val_loss: 262.8108 - val_rmse: 13.7706\n",
      "Epoch 11/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 293.4625 - rmse: 15.0055 - val_loss: 1701.9113 - val_rmse: 39.7842\n",
      "Epoch 12/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 448.6657 - rmse: 17.2898 - val_loss: 223.5582 - val_rmse: 12.8865\n",
      "Epoch 13/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 284.6246 - rmse: 14.5244 - val_loss: 194.5061 - val_rmse: 12.2066\n",
      "Epoch 14/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 258.5812 - rmse: 13.9253 - val_loss: 576.5175 - val_rmse: 23.2960\n",
      "Epoch 15/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 260.0004 - rmse: 14.3560 - val_loss: 700.7418 - val_rmse: 25.5821\n",
      "Epoch 16/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 281.0966 - rmse: 14.7191 - val_loss: 241.3247 - val_rmse: 13.6296\n",
      "Epoch 17/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 294.9035 - rmse: 15.2316 - val_loss: 950.6000 - val_rmse: 29.2247\n",
      "Epoch 18/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 289.0583 - rmse: 14.3757 - val_loss: 1258.8749 - val_rmse: 31.0504\n",
      "Epoch 19/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 439.2669 - rmse: 16.0989 - val_loss: 2427.2678 - val_rmse: 46.9406\n",
      "Epoch 20/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 314.9400 - rmse: 14.6678 - val_loss: 373.8055 - val_rmse: 17.8940\n",
      "Epoch 21/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 200.1806 - rmse: 12.9942 - val_loss: 176.2676 - val_rmse: 11.7616\n",
      "Epoch 22/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 338.3154 - rmse: 15.1373 - val_loss: 137.7838 - val_rmse: 11.1602\n",
      "Epoch 23/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 288.9297 - rmse: 14.5148 - val_loss: 331.5243 - val_rmse: 14.8690\n",
      "Epoch 24/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 194.2886 - rmse: 12.6289 - val_loss: 143.8005 - val_rmse: 10.6800\n",
      "Epoch 25/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 298.8408 - rmse: 14.2853 - val_loss: 124.6859 - val_rmse: 10.4964\n",
      "Epoch 26/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 259.8902 - rmse: 13.8459 - val_loss: 420.1764 - val_rmse: 19.7083\n",
      "Epoch 27/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 206.5056 - rmse: 12.6608 - val_loss: 202.1306 - val_rmse: 13.6507\n",
      "Epoch 28/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 265.8112 - rmse: 14.2158 - val_loss: 217.5708 - val_rmse: 13.8335\n",
      "Epoch 29/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 303.1452 - rmse: 14.4763 - val_loss: 126.2515 - val_rmse: 10.6494\n",
      "Epoch 30/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 329.2209 - rmse: 14.5808 - val_loss: 147.2131 - val_rmse: 11.6633\n",
      "Epoch 31/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 190.8306 - rmse: 12.4845 - val_loss: 126.8078 - val_rmse: 10.6848\n",
      "Epoch 32/50\n",
      "1750/1750 [==============================] - 2s 1ms/step - loss: 278.2802 - rmse: 14.0759 - val_loss: 156.9659 - val_rmse: 11.8250\n",
      "Epoch 33/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 259.6971 - rmse: 14.0762 - val_loss: 128.0573 - val_rmse: 10.7487\n",
      "Epoch 34/50\n",
      "1750/1750 [==============================] - 3s 1ms/step - loss: 192.0137 - rmse: 12.5689 - val_loss: 185.9062 - val_rmse: 13.2870\n",
      "Epoch 35/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 250.3950 - rmse: 13.8197 - val_loss: 601.1135 - val_rmse: 23.7297\n",
      "Epoch 36/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 437.7906 - rmse: 15.0634 - val_loss: 108.1307 - val_rmse: 9.9877\n",
      "Epoch 37/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 184.4151 - rmse: 12.0612 - val_loss: 136.7495 - val_rmse: 11.2261\n",
      "Epoch 38/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 227.7648 - rmse: 13.4912 - val_loss: 152.4305 - val_rmse: 11.9713\n",
      "Epoch 39/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 263.2148 - rmse: 13.2680 - val_loss: 165.7339 - val_rmse: 12.3787\n",
      "Epoch 40/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 237.8972 - rmse: 13.5530 - val_loss: 178.4414 - val_rmse: 12.8376\n",
      "Epoch 41/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 311.1243 - rmse: 14.1567 - val_loss: 144.4186 - val_rmse: 11.3334\n",
      "Epoch 42/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 217.2371 - rmse: 12.4544 - val_loss: 124.6210 - val_rmse: 10.6528\n",
      "Epoch 43/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 171.5281 - rmse: 12.0547 - val_loss: 466.1050 - val_rmse: 19.6976\n",
      "Epoch 44/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 274.2271 - rmse: 13.7468 - val_loss: 98.7312 - val_rmse: 9.4872\n",
      "Epoch 45/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 241.7198 - rmse: 13.2420 - val_loss: 135.2626 - val_rmse: 11.0838\n",
      "Epoch 46/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 252.8849 - rmse: 13.1044 - val_loss: 130.3038 - val_rmse: 10.9879\n",
      "Epoch 47/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 228.5492 - rmse: 12.7359 - val_loss: 152.8094 - val_rmse: 12.1277\n",
      "Epoch 48/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 207.4045 - rmse: 12.3516 - val_loss: 133.0616 - val_rmse: 10.9649\n",
      "Epoch 49/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 288.9352 - rmse: 13.3627 - val_loss: 111.2777 - val_rmse: 10.0451\n",
      "Epoch 50/50\n",
      "1750/1750 [==============================] - 3s 2ms/step - loss: 428.2646 - rmse: 14.8459 - val_loss: 125.9221 - val_rmse: 10.6526\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 146.4466 - rmse: 11.0118\n",
      "Loss en el conjunto de prueba: 146.44664001464844\n",
      "RMSE en el conjunto de prueba: 11.011801719665527\n",
      "487/487 [==============================] - 1s 1ms/step\n",
      "PredicciÃ³n: 2004.4021 AÃ±o real: 2012\n",
      "PredicciÃ³n: 2003.2338 AÃ±o real: 2012\n",
      "PredicciÃ³n: 1996.6223 AÃ±o real: 1998\n",
      "PredicciÃ³n: 1999.315 AÃ±o real: 1996\n",
      "PredicciÃ³n: 1995.8253 AÃ±o real: 1998\n",
      "PredicciÃ³n: 2004.4958 AÃ±o real: 2009\n",
      "PredicciÃ³n: 2011.8496 AÃ±o real: 2008\n",
      "PredicciÃ³n: 2007.5424 AÃ±o real: 2005\n",
      "PredicciÃ³n: 2003.5148 AÃ±o real: 2013\n",
      "PredicciÃ³n: 1989.6185 AÃ±o real: 1981\n"
     ]
    }
   ],
   "source": [
    "# 2024/04/23\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Definir RMSE como mÃ©trica personalizada\n",
    "def rmse(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "\n",
    "# Dividir los datos en caracterÃ­sticas (X) y variable dependiente (y)\n",
    "X = data.drop(['ID', 'Y'], axis=1).values\n",
    "y = data['Y'].values\n",
    "\n",
    "# Normalizar las caracterÃ­sticas\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compilar el modelo con RMSE como mÃ©trica\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[rmse])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, rmse_score = model.evaluate(X_test, y_test)\n",
    "print(\"Loss en el conjunto de prueba:\", loss)\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Imprimir algunas predicciones y valores reales para comparar\n",
    "for i in range(10):\n",
    "    print(\"PredicciÃ³n:\", predictions[i][0], \"AÃ±o real:\", y_test[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelecciÃ²n de caracteristicas por filtrado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caracteristicas:  9\n",
      "caracteristicas seleccionadas ['V1', 'V5', 'V8', 'V11', 'V36', 'V40', 'V46', 'V63', 'V69']\n",
      "Epoch 1/50\n",
      "1362/1362 [==============================] - 4s 2ms/step - loss: 1376249.5000 - root_mean_squared_error: 1173.1366 - val_loss: 3036.3254 - val_root_mean_squared_error: 55.1029\n",
      "Epoch 2/50\n",
      "1362/1362 [==============================] - 3s 3ms/step - loss: 3065.5710 - root_mean_squared_error: 55.3676 - val_loss: 2961.6406 - val_root_mean_squared_error: 54.4210\n",
      "Epoch 3/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 2901.4858 - root_mean_squared_error: 53.8654 - val_loss: 2678.5120 - val_root_mean_squared_error: 51.7543\n",
      "Epoch 4/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 2494.8618 - root_mean_squared_error: 49.9486 - val_loss: 2222.6509 - val_root_mean_squared_error: 47.1450\n",
      "Epoch 5/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 2046.8860 - root_mean_squared_error: 45.2425 - val_loss: 1847.7590 - val_root_mean_squared_error: 42.9856\n",
      "Epoch 6/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 1716.9670 - root_mean_squared_error: 41.4363 - val_loss: 1620.8842 - val_root_mean_squared_error: 40.2602\n",
      "Epoch 7/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 1507.2738 - root_mean_squared_error: 38.8236 - val_loss: 1437.9540 - val_root_mean_squared_error: 37.9204\n",
      "Epoch 8/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 1362.2617 - root_mean_squared_error: 36.9088 - val_loss: 1336.8896 - val_root_mean_squared_error: 36.5635\n",
      "Epoch 9/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 1246.0383 - root_mean_squared_error: 35.2993 - val_loss: 1204.5740 - val_root_mean_squared_error: 34.7070\n",
      "Epoch 10/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 1137.3224 - root_mean_squared_error: 33.7242 - val_loss: 1094.7146 - val_root_mean_squared_error: 33.0865\n",
      "Epoch 11/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 1029.0468 - root_mean_squared_error: 32.0788 - val_loss: 992.9510 - val_root_mean_squared_error: 31.5111\n",
      "Epoch 12/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 925.3285 - root_mean_squared_error: 30.4192 - val_loss: 881.0690 - val_root_mean_squared_error: 29.6828\n",
      "Epoch 13/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 824.9227 - root_mean_squared_error: 28.7215 - val_loss: 778.8344 - val_root_mean_squared_error: 27.9076\n",
      "Epoch 14/50\n",
      "1362/1362 [==============================] - 6s 5ms/step - loss: 726.2484 - root_mean_squared_error: 26.9490 - val_loss: 680.5201 - val_root_mean_squared_error: 26.0868\n",
      "Epoch 15/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 631.5784 - root_mean_squared_error: 25.1312 - val_loss: 586.0948 - val_root_mean_squared_error: 24.2094\n",
      "Epoch 16/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 539.3700 - root_mean_squared_error: 23.2243 - val_loss: 520.1763 - val_root_mean_squared_error: 22.8074\n",
      "Epoch 17/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 452.9041 - root_mean_squared_error: 21.2815 - val_loss: 411.9598 - val_root_mean_squared_error: 20.2968\n",
      "Epoch 18/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 375.5033 - root_mean_squared_error: 19.3779 - val_loss: 357.3087 - val_root_mean_squared_error: 18.9026\n",
      "Epoch 19/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 306.5758 - root_mean_squared_error: 17.5093 - val_loss: 286.8991 - val_root_mean_squared_error: 16.9381\n",
      "Epoch 20/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 249.0878 - root_mean_squared_error: 15.7825 - val_loss: 238.7489 - val_root_mean_squared_error: 15.4515\n",
      "Epoch 21/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 204.9885 - root_mean_squared_error: 14.3174 - val_loss: 187.5509 - val_root_mean_squared_error: 13.6949\n",
      "Epoch 22/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 169.0255 - root_mean_squared_error: 13.0010 - val_loss: 153.1356 - val_root_mean_squared_error: 12.3748\n",
      "Epoch 23/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 148.0115 - root_mean_squared_error: 12.1660 - val_loss: 134.9960 - val_root_mean_squared_error: 11.6188\n",
      "Epoch 24/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 132.9934 - root_mean_squared_error: 11.5323 - val_loss: 127.2315 - val_root_mean_squared_error: 11.2797\n",
      "Epoch 25/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 123.7729 - root_mean_squared_error: 11.1253 - val_loss: 123.2845 - val_root_mean_squared_error: 11.1034\n",
      "Epoch 26/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 118.5670 - root_mean_squared_error: 10.8888 - val_loss: 112.7391 - val_root_mean_squared_error: 10.6179\n",
      "Epoch 27/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 114.3623 - root_mean_squared_error: 10.6940 - val_loss: 109.5538 - val_root_mean_squared_error: 10.4668\n",
      "Epoch 28/50\n",
      "1362/1362 [==============================] - 6s 5ms/step - loss: 112.4395 - root_mean_squared_error: 10.6037 - val_loss: 110.3331 - val_root_mean_squared_error: 10.5040\n",
      "Epoch 29/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 110.5494 - root_mean_squared_error: 10.5142 - val_loss: 106.6940 - val_root_mean_squared_error: 10.3293\n",
      "Epoch 30/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 110.1894 - root_mean_squared_error: 10.4971 - val_loss: 106.1438 - val_root_mean_squared_error: 10.3026\n",
      "Epoch 31/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 110.2214 - root_mean_squared_error: 10.4986 - val_loss: 106.7911 - val_root_mean_squared_error: 10.3340\n",
      "Epoch 32/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 109.3157 - root_mean_squared_error: 10.4554 - val_loss: 108.8692 - val_root_mean_squared_error: 10.4340\n",
      "Epoch 33/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 108.9564 - root_mean_squared_error: 10.4382 - val_loss: 107.3967 - val_root_mean_squared_error: 10.3632\n",
      "Epoch 34/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 109.7103 - root_mean_squared_error: 10.4743 - val_loss: 104.4439 - val_root_mean_squared_error: 10.2198\n",
      "Epoch 35/50\n",
      "1362/1362 [==============================] - 7s 5ms/step - loss: 109.4436 - root_mean_squared_error: 10.4615 - val_loss: 108.7380 - val_root_mean_squared_error: 10.4278\n",
      "Epoch 36/50\n",
      "1362/1362 [==============================] - 6s 5ms/step - loss: 109.0410 - root_mean_squared_error: 10.4423 - val_loss: 104.6591 - val_root_mean_squared_error: 10.2303\n",
      "Epoch 37/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 108.5455 - root_mean_squared_error: 10.4185 - val_loss: 104.2561 - val_root_mean_squared_error: 10.2106\n",
      "Epoch 38/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 108.7400 - root_mean_squared_error: 10.4278 - val_loss: 105.8211 - val_root_mean_squared_error: 10.2869\n",
      "Epoch 39/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 109.4131 - root_mean_squared_error: 10.4601 - val_loss: 110.0290 - val_root_mean_squared_error: 10.4895\n",
      "Epoch 40/50\n",
      "1362/1362 [==============================] - 6s 5ms/step - loss: 108.6244 - root_mean_squared_error: 10.4223 - val_loss: 105.3965 - val_root_mean_squared_error: 10.2663\n",
      "Epoch 41/50\n",
      "1362/1362 [==============================] - 6s 5ms/step - loss: 108.0621 - root_mean_squared_error: 10.3953 - val_loss: 114.1149 - val_root_mean_squared_error: 10.6825\n",
      "Epoch 42/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 109.8045 - root_mean_squared_error: 10.4788 - val_loss: 127.7227 - val_root_mean_squared_error: 11.3014\n",
      "Epoch 43/50\n",
      "1362/1362 [==============================] - 6s 5ms/step - loss: 108.7266 - root_mean_squared_error: 10.4272 - val_loss: 109.8547 - val_root_mean_squared_error: 10.4812\n",
      "Epoch 44/50\n",
      "1362/1362 [==============================] - 7s 5ms/step - loss: 108.6804 - root_mean_squared_error: 10.4250 - val_loss: 106.3292 - val_root_mean_squared_error: 10.3116\n",
      "Epoch 45/50\n",
      "1362/1362 [==============================] - 7s 5ms/step - loss: 107.5823 - root_mean_squared_error: 10.3722 - val_loss: 104.3758 - val_root_mean_squared_error: 10.2164\n",
      "Epoch 46/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 109.2910 - root_mean_squared_error: 10.4542 - val_loss: 105.7510 - val_root_mean_squared_error: 10.2835\n",
      "Epoch 47/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 108.5983 - root_mean_squared_error: 10.4211 - val_loss: 111.1718 - val_root_mean_squared_error: 10.5438\n",
      "Epoch 48/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 108.8392 - root_mean_squared_error: 10.4326 - val_loss: 106.2940 - val_root_mean_squared_error: 10.3099\n",
      "Epoch 49/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 108.8787 - root_mean_squared_error: 10.4345 - val_loss: 103.8186 - val_root_mean_squared_error: 10.1891\n",
      "Epoch 50/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 108.5449 - root_mean_squared_error: 10.4185 - val_loss: 103.6729 - val_root_mean_squared_error: 10.1820\n",
      "730/730 [==============================] - 2s 3ms/step - loss: 103.3031 - root_mean_squared_error: 10.1638\n",
      "730/730 [==============================] - 2s 3ms/step - loss: 103.3031 - root_mean_squared_error: 10.1638\n",
      "Loss en el conjunto de prueba: 103.30313110351562\n",
      "RMSE en el conjunto de prueba: 10.163814544677734\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Separar las caracterÃ­sticas (X) y la variable objetivo (y)\n",
    "\n",
    "data.dropna\n",
    "\n",
    "\n",
    "X = data.drop(['ID', 'Y', 'V3'], axis=1)\n",
    "y = data['Y']\n",
    "\n",
    "# Calcular correlaciones entre caracterÃ­sticas y variable objetivo\n",
    "correlations = {col: X[col].corr(y) for col in X.columns}\n",
    "\n",
    "# Seleccionar caracterÃ­sticas con alta correlaciÃ³n (por ejemplo, |correlaciÃ³n| > 0.09)\n",
    "selected_features = [col for col in correlations if abs(correlations[col]) > 0.1]\n",
    "\n",
    "# Reducir el conjunto de datos a las caracterÃ­sticas seleccionadas\n",
    "X_filtered = X[selected_features]\n",
    "\n",
    "print('caracteristicas: ', len(selected_features))\n",
    "\n",
    "print('caracteristicas seleccionadas', selected_features)\n",
    "\n",
    "\n",
    "# Usar X_filtered para entrenar el modelo de red neuronal\n",
    "\n",
    "# Normalizar las caracterÃ­sticas\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X_filtered)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compilar el modelo con RMSE como mÃ©trica\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, return_dict=True)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, rmse_score = model.evaluate(X_test, y_test)\n",
    "print(\"Loss en el conjunto de prueba:\", loss)\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SelecciÃ²n de caracteristicas por envoltura "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1362/1362 [==============================] - 7s 4ms/step - loss: 568191.1875 - root_mean_squared_error: 753.7845 - val_loss: 7175.7437 - val_root_mean_squared_error: 84.7098\n",
      "Epoch 2/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 5828.3721 - root_mean_squared_error: 76.3438 - val_loss: 4610.8945 - val_root_mean_squared_error: 67.9036\n",
      "Epoch 3/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 3530.6475 - root_mean_squared_error: 59.4193 - val_loss: 2710.2251 - val_root_mean_squared_error: 52.0598\n",
      "Epoch 4/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 2211.1787 - root_mean_squared_error: 47.0232 - val_loss: 1750.2842 - val_root_mean_squared_error: 41.8364\n",
      "Epoch 5/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 1502.1011 - root_mean_squared_error: 38.7570 - val_loss: 1213.5952 - val_root_mean_squared_error: 34.8367\n",
      "Epoch 6/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 1054.9961 - root_mean_squared_error: 32.4807 - val_loss: 836.4858 - val_root_mean_squared_error: 28.9221\n",
      "Epoch 7/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 740.7198 - root_mean_squared_error: 27.2162 - val_loss: 582.3105 - val_root_mean_squared_error: 24.1311\n",
      "Epoch 8/50\n",
      "1362/1362 [==============================] - 6s 5ms/step - loss: 513.3733 - root_mean_squared_error: 22.6577 - val_loss: 403.8894 - val_root_mean_squared_error: 20.0970\n",
      "Epoch 9/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 363.1439 - root_mean_squared_error: 19.0563 - val_loss: 288.3541 - val_root_mean_squared_error: 16.9810\n",
      "Epoch 10/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 251.6369 - root_mean_squared_error: 15.8631 - val_loss: 196.6477 - val_root_mean_squared_error: 14.0231\n",
      "Epoch 11/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 179.5746 - root_mean_squared_error: 13.4005 - val_loss: 145.7386 - val_root_mean_squared_error: 12.0722\n",
      "Epoch 12/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 139.8268 - root_mean_squared_error: 11.8248 - val_loss: 123.3278 - val_root_mean_squared_error: 11.1053\n",
      "Epoch 13/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 120.3981 - root_mean_squared_error: 10.9726 - val_loss: 117.9383 - val_root_mean_squared_error: 10.8599\n",
      "Epoch 14/50\n",
      "1362/1362 [==============================] - 2s 2ms/step - loss: 113.9308 - root_mean_squared_error: 10.6738 - val_loss: 115.9091 - val_root_mean_squared_error: 10.7661\n",
      "Epoch 15/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 107.7576 - root_mean_squared_error: 10.3806 - val_loss: 158.9426 - val_root_mean_squared_error: 12.6072\n",
      "Epoch 16/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 105.7321 - root_mean_squared_error: 10.2826 - val_loss: 105.7933 - val_root_mean_squared_error: 10.2856\n",
      "Epoch 17/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 105.2939 - root_mean_squared_error: 10.2613 - val_loss: 96.3597 - val_root_mean_squared_error: 9.8163\n",
      "Epoch 18/50\n",
      "1362/1362 [==============================] - 3s 3ms/step - loss: 104.7948 - root_mean_squared_error: 10.2369 - val_loss: 120.5840 - val_root_mean_squared_error: 10.9811\n",
      "Epoch 19/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 105.0726 - root_mean_squared_error: 10.2505 - val_loss: 95.7526 - val_root_mean_squared_error: 9.7853\n",
      "Epoch 20/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 105.4934 - root_mean_squared_error: 10.2710 - val_loss: 100.4095 - val_root_mean_squared_error: 10.0205\n",
      "Epoch 21/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 104.8810 - root_mean_squared_error: 10.2411 - val_loss: 106.7655 - val_root_mean_squared_error: 10.3327\n",
      "Epoch 22/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.5577 - root_mean_squared_error: 10.1763 - val_loss: 142.2167 - val_root_mean_squared_error: 11.9255\n",
      "Epoch 23/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 104.0217 - root_mean_squared_error: 10.1991 - val_loss: 112.7241 - val_root_mean_squared_error: 10.6172\n",
      "Epoch 24/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 103.3437 - root_mean_squared_error: 10.1658 - val_loss: 103.7955 - val_root_mean_squared_error: 10.1880\n",
      "Epoch 25/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 103.9517 - root_mean_squared_error: 10.1957 - val_loss: 113.4892 - val_root_mean_squared_error: 10.6531\n",
      "Epoch 26/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 104.2824 - root_mean_squared_error: 10.2119 - val_loss: 96.2455 - val_root_mean_squared_error: 9.8105\n",
      "Epoch 27/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.4246 - root_mean_squared_error: 10.1698 - val_loss: 125.6477 - val_root_mean_squared_error: 11.2093\n",
      "Epoch 28/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 105.1273 - root_mean_squared_error: 10.2532 - val_loss: 101.1333 - val_root_mean_squared_error: 10.0565\n",
      "Epoch 29/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 102.8733 - root_mean_squared_error: 10.1426 - val_loss: 100.3714 - val_root_mean_squared_error: 10.0186\n",
      "Epoch 30/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 102.9890 - root_mean_squared_error: 10.1484 - val_loss: 93.8674 - val_root_mean_squared_error: 9.6885\n",
      "Epoch 31/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 104.0652 - root_mean_squared_error: 10.2012 - val_loss: 109.6015 - val_root_mean_squared_error: 10.4691\n",
      "Epoch 32/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.2760 - root_mean_squared_error: 10.1625 - val_loss: 96.8312 - val_root_mean_squared_error: 9.8403\n",
      "Epoch 33/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.9218 - root_mean_squared_error: 10.1942 - val_loss: 98.5981 - val_root_mean_squared_error: 9.9297\n",
      "Epoch 34/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 102.5229 - root_mean_squared_error: 10.1254 - val_loss: 110.5606 - val_root_mean_squared_error: 10.5148\n",
      "Epoch 35/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 102.7379 - root_mean_squared_error: 10.1360 - val_loss: 96.3149 - val_root_mean_squared_error: 9.8140\n",
      "Epoch 36/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 102.7421 - root_mean_squared_error: 10.1362 - val_loss: 93.3013 - val_root_mean_squared_error: 9.6593\n",
      "Epoch 37/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.3247 - root_mean_squared_error: 10.1649 - val_loss: 120.9909 - val_root_mean_squared_error: 10.9996\n",
      "Epoch 38/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 101.4706 - root_mean_squared_error: 10.0733 - val_loss: 123.8103 - val_root_mean_squared_error: 11.1270\n",
      "Epoch 39/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 104.6128 - root_mean_squared_error: 10.2280 - val_loss: 133.8170 - val_root_mean_squared_error: 11.5679\n",
      "Epoch 40/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 103.1106 - root_mean_squared_error: 10.1543 - val_loss: 96.4690 - val_root_mean_squared_error: 9.8219\n",
      "Epoch 41/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.3419 - root_mean_squared_error: 10.1657 - val_loss: 100.4314 - val_root_mean_squared_error: 10.0215\n",
      "Epoch 42/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 102.2803 - root_mean_squared_error: 10.1134 - val_loss: 93.5004 - val_root_mean_squared_error: 9.6696\n",
      "Epoch 43/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 102.8660 - root_mean_squared_error: 10.1423 - val_loss: 93.6022 - val_root_mean_squared_error: 9.6748\n",
      "Epoch 44/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.4020 - root_mean_squared_error: 10.1687 - val_loss: 97.8525 - val_root_mean_squared_error: 9.8920\n",
      "Epoch 45/50\n",
      "1362/1362 [==============================] - 3s 2ms/step - loss: 103.0241 - root_mean_squared_error: 10.1501 - val_loss: 103.6144 - val_root_mean_squared_error: 10.1791\n",
      "Epoch 46/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 102.3920 - root_mean_squared_error: 10.1189 - val_loss: 119.6084 - val_root_mean_squared_error: 10.9366\n",
      "Epoch 47/50\n",
      "1362/1362 [==============================] - 4s 3ms/step - loss: 102.5243 - root_mean_squared_error: 10.1254 - val_loss: 103.1951 - val_root_mean_squared_error: 10.1585\n",
      "Epoch 48/50\n",
      "1362/1362 [==============================] - 5s 4ms/step - loss: 101.6820 - root_mean_squared_error: 10.0837 - val_loss: 135.4903 - val_root_mean_squared_error: 11.6400\n",
      "Epoch 49/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 104.4298 - root_mean_squared_error: 10.2191 - val_loss: 93.4485 - val_root_mean_squared_error: 9.6669\n",
      "Epoch 50/50\n",
      "1362/1362 [==============================] - 6s 4ms/step - loss: 103.5433 - root_mean_squared_error: 10.1756 - val_loss: 97.6520 - val_root_mean_squared_error: 9.8819\n",
      "730/730 [==============================] - 2s 3ms/step - loss: 98.4156 - root_mean_squared_error: 9.9205\n",
      "730/730 [==============================] - 2s 3ms/step - loss: 98.4156 - root_mean_squared_error: 9.9205\n",
      "Loss en el conjunto de prueba: 98.4156494140625\n",
      "RMSE en el conjunto de prueba: 9.920466423034668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# Separar las caracterÃ­sticas (X) y la variable objetivo (y)\n",
    "X = data.drop(['ID', 'Y', 'V3'], axis=1)\n",
    "y = data['Y']\n",
    "\n",
    "# Crear un modelo de regresiÃ³n lineal\n",
    "estimator = LinearRegression()\n",
    "\n",
    "# Seleccionar caracterÃ­sticas usando RFE con 10 caracterÃ­sticas restantes\n",
    "selector = RFE(estimator, n_features_to_select=10)\n",
    "\n",
    "# Ajustar el selector a las caracterÃ­sticas y la variable objetivo\n",
    "selector.fit(X, y)\n",
    "\n",
    "# Obtener las caracterÃ­sticas seleccionadas\n",
    "selected_features = X.columns[selector.support_]\n",
    "\n",
    "# Reducir el conjunto de datos a las caracterÃ­sticas seleccionadas\n",
    "X_wrapped = X[selected_features]\n",
    "\n",
    "# Usar X_wrapped para entrenar el modelo de red neuronal\n",
    "# Normalizar las caracterÃ­sticas\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X_wrapped)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "# Compilar el modelo con RMSE como mÃ©trica\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, return_dict=True)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "loss, rmse_score = model.evaluate(X_test, y_test)\n",
    "print(\"Loss en el conjunto de prueba:\", loss)\n",
    "print(\"RMSE en el conjunto de prueba:\", rmse_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion aleatoria envoltura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Crear una lista de modelos de estimaciÃ³n\n",
    "estimators = [LinearRegression(), RandomForestRegressor(), SVR()]\n",
    "\n",
    "# Crear una lista de nÃºmeros de caracterÃ­sticas a seleccionar\n",
    "features_to_select = [5, 10, 15, 20]\n",
    "\n",
    "# Inicializar el mejor RMSE a un nÃºmero alto\n",
    "best_rmse = float('inf')\n",
    "\n",
    "# Inicializar el mejor modelo y el nÃºmero de caracterÃ­sticas\n",
    "best_estimator = None\n",
    "best_n_features = None\n",
    "\n",
    "for estimator in estimators:\n",
    "    for n in features_to_select:\n",
    "        # Seleccionar caracterÃ­sticas usando RFE\n",
    "        selector = RFE(estimator, n_features_to_select=n)\n",
    "        selector = selector.fit(X, y)\n",
    "        selected_features = X.columns[selector.support_]\n",
    "        X_wrapped = X[selected_features]\n",
    "\n",
    "        # Normalizar las caracterÃ­sticas\n",
    "        scaler = MinMaxScaler()\n",
    "        X = scaler.fit_transform(X_wrapped)\n",
    "\n",
    "        # Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1, activation='linear'))\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss=MeanSquaredError(), metrics=[RootMeanSquaredError()])\n",
    "        model.fit(X_train, y_train, batch_size=32, epochs=50, validation_split=0.2)\n",
    "\n",
    "        # Evaluar el modelo en el conjunto de prueba\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        # Si el RMSE es menor que el mejor RMSE hasta ahora, actualizar el mejor RMSE, el mejor modelo y el nÃºmero de caracterÃ­sticas\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_estimator = estimator\n",
    "            best_n_features = n\n",
    "\n",
    "print(\"Mejor RMSE:\", best_rmse)\n",
    "print(\"Mejor modelo de estimaciÃ³n:\", best_estimator)\n",
    "print(\"Mejor nÃºmero de caracterÃ­sticas:\", best_n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V4', 'V6', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13'], dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = X.columns[selector.support_]\n",
    "\n",
    "selected_features\n",
    "\n",
    "#X_wrapped = X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from math import sqrt\n",
    "\n",
    "# Cargar los datos\n",
    "train_data = pd.read_csv('trainReg.csv')\n",
    "test_data = pd.read_csv('testReg.csv')\n",
    "\n",
    "# Preparar los datos de entrenamiento y prueba\n",
    "X = train_data.drop(columns=['ID', 'Y'])\n",
    "y = train_data['Y']\n",
    "X_test = test_data.drop(columns=['ID'])\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validaciÃ³n\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Elastic Net para seleccionar caracterÃ­sticas\n",
    "model_enet = ElasticNetCV(cv=5, random_state=0, l1_ratio=[.1, .5, .7, .9, .95, .99, 1], alphas=np.logspace(-4, -0.5, 30))\n",
    "model_enet.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Importancia de las caracterÃ­sticas y selecciÃ³n\n",
    "importance = np.abs(model_enet.coef_)\n",
    "selected_features = importance > np.sort(importance)[::-1][60]  # seleccionar las 60 caracterÃ­sticas mÃ¡s importantes\n",
    "X_train_selected = X_train_scaled[:, selected_features]\n",
    "X_val_selected = X_val_scaled[:, selected_features]\n",
    "X_test_selected = X_test_scaled[:, selected_features]\n",
    "\n",
    "# DefiniciÃ³n de la funciÃ³n para construir el modelo\n",
    "def build_optimized_model(layers_info, dropout_rate):\n",
    "    model = Sequential()\n",
    "    for i, (neurons, use_bn) in enumerate(layers_info):\n",
    "        if i == 0:\n",
    "            model.add(Dense(neurons, activation='relu', input_shape=(X_train_selected.shape[1],)))\n",
    "        else:\n",
    "            model.add(Dense(neurons, activation='relu'))\n",
    "        if use_bn:\n",
    "            model.add(BatchNormalization())\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "further_refined_configurations = [\n",
    "\n",
    "    ([ (160, True), (80, True), (45, True), (25, True), (20, True) ], 0.0),\n",
    "    ([ (160, True), (80, True), (45, True), (25, True), (15, True) ], 0.0),\n",
    "    ([ (160, True), (80, True), (45, True), (25, True), (8, True) ], 0.0),\n",
    "    ([ (160, True), (80, True), (45, True), (25, True), (10, True) ], 0.0),# AÃ±adir una capa adicional\n",
    "]\n",
    "\n",
    "# Evaluar las configuraciones refinadas adicionales\n",
    "further_refined_results = {}\n",
    "for index, (layers_info, dropout_rate) in enumerate(further_refined_configurations):\n",
    "    model = build_optimized_model(layers_info, dropout_rate)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    model.fit(X_train_selected, y_train, validation_data=(X_val_selected, y_val), epochs=100, batch_size=10, callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)])\n",
    "    y_pred = model.predict(X_val_selected)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_pred))\n",
    "    further_refined_results[f'Further Refined Modelo {index+1}'] = rmse\n",
    "\n",
    "# Determinar el mejor modelo de las variaciones adicionales\n",
    "best_further_refined_model = min(further_refined_results, key=further_refined_results.get)\n",
    "best_further_refined_rmse = further_refined_results[best_further_refined_model]\n",
    "\n",
    "print(\"RMSEs de las variaciones adicionales refinadas de modelos optimizados:\", further_refined_results)\n",
    "print(\"La mejor variaciÃ³n adicional refinada de modelo es\", best_further_refined_model, \"con un RMSE de\", best_further_refined_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
